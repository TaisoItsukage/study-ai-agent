import { Genre } from "../types";

export const llm: Genre = {
  id: "llm",
  name: "大規模言語モデル (LLM)",
  description: "ChatGPTやClaudeなどの大規模言語モデルの仕組みと特徴を学びます。最も注目されているAI技術の基礎を理解しましょう。",
  icon: "💬",
  questions: [
    // === LLMの基本概念（1-20） ===
    {
      id: "llm-001",
      question: "LLMは何の略称ですか？",
      options: [
        "Large Language Model",
        "Learning Language Machine",
        "Logical Language Method",
        "Limited Language Module"
      ],
      correctIndex: 0,
      explanation: "LLMは「Large Language Model（大規模言語モデル）」の略です。膨大なテキストデータで学習し、人間のような自然な文章を生成できるAIモデルのことを指します。営業では「大規模言語モデル」と正式名称で説明すると、専門性をアピールできます。"
    },
    {
      id: "llm-002",
      question: "LLMが文章を生成する基本的な仕組みはどれですか？",
      options: [
        "インターネットからリアルタイムで文章を検索してコピーする",
        "次に来る可能性が高い単語を予測して順番に生成する",
        "あらかじめ用意された文章テンプレートを選択する",
        "人間のオペレーターが裏で文章を作成している"
      ],
      correctIndex: 1,
      explanation: "LLMは「次にどの単語が来る確率が高いか」を予測することで文章を生成します。お客様には「AIが学習したパターンから最も自然な言葉を選んでいる」と説明すると理解されやすいです。リアルタイム検索ではないことを伝えることで、情報の鮮度に関する誤解も防げます。"
    },
    {
      id: "llm-003",
      question: "「トークン」とはLLMにおいて何を指しますか？",
      options: [
        "AIサービスの利用料金の単位",
        "テキストを処理する際の最小単位（単語や文字の塊）",
        "AIモデルのセキュリティ認証キー",
        "ユーザーのログイン情報"
      ],
      correctIndex: 1,
      explanation: "トークンは、LLMがテキストを処理する際の最小単位です。英語では1単語が約1トークン、日本語では1文字が約1〜2トークンになります。営業時には「料金は処理するテキストの量（トークン数）で決まります」と説明し、見積もりの根拠として活用しましょう。"
    },
    {
      id: "llm-004",
      question: "「コンテキストウィンドウ」とは何を指しますか？",
      options: [
        "AIが表示されるブラウザの画面サイズ",
        "AIが一度に処理できるテキストの最大量",
        "AIの応答が表示されるウィンドウ",
        "AIの設定画面のこと"
      ],
      correctIndex: 1,
      explanation: "コンテキストウィンドウは、LLMが一度の会話で記憶・処理できるテキストの最大量（トークン数）を指します。例えば「128Kトークン対応」は、長文ドキュメントや長い会話履歴を扱えることを意味します。お客様の用途に応じて、適切なコンテキストウィンドウを持つモデルを提案しましょう。"
    },
    {
      id: "llm-005",
      question: "LLMの「パラメータ数」が大きいとどのような傾向がありますか？",
      options: [
        "処理速度が速くなる",
        "より複雑なタスクを処理できる可能性が高まる",
        "消費電力が減る",
        "料金が安くなる"
      ],
      correctIndex: 1,
      explanation: "パラメータ数は、モデルが持つ学習可能な変数の数です。一般的にパラメータ数が多いほど複雑なタスクを処理できますが、計算コストも増加します。営業では「パラメータ数が多い＝高性能」と単純化せず、用途に適したモデル選びが重要と伝えましょう。"
    },
    {
      id: "llm-006",
      question: "「事前学習（Pre-training）」とは何ですか？",
      options: [
        "ユーザーが使用前に行う設定作業",
        "大量のテキストデータでモデルの基礎能力を学習させること",
        "AIを使う前のテスト運用期間",
        "営業担当者向けの研修"
      ],
      correctIndex: 1,
      explanation: "事前学習は、インターネット上の大量のテキストデータを使ってLLMに言語の基礎を学習させるプロセスです。この段階で文法、知識、推論能力などを獲得します。お客様には「基礎教育を受けた状態のAI」と例えると分かりやすいです。"
    },
    {
      id: "llm-007",
      question: "LLMの「推論（Inference）」とは何ですか？",
      options: [
        "AIが新しい知識を学習すること",
        "学習済みモデルを使ってユーザーの質問に回答を生成すること",
        "AIが自分の間違いを修正すること",
        "AIが他のAIと通信すること"
      ],
      correctIndex: 1,
      explanation: "推論は、学習済みのLLMが実際にユーザーの入力に対して回答を生成する処理です。API利用料金は主にこの推論処理に対して発生します。営業では「学習は開発会社が行い、お客様は推論（利用）部分の料金を払う」と説明しましょう。"
    },
    {
      id: "llm-008",
      question: "「Transformer」アーキテクチャとは何ですか？",
      options: [
        "変形するロボットの設計図",
        "現代のLLMの基盤となる深層学習の構造",
        "電力を変換する装置",
        "データ形式を変換するツール"
      ],
      correctIndex: 1,
      explanation: "TransformerはGoogleが2017年に発表した深層学習アーキテクチャで、GPTやClaudeなど現代のLLMの基盤です。Attention機構により文章全体の関係性を効率的に捉えられます。技術的な質問には「最先端のTransformer技術を採用」と答えられると信頼感が増します。"
    },
    {
      id: "llm-009",
      question: "LLMにおける「Attention機構」の役割は何ですか？",
      options: [
        "ユーザーの注意を引くための機能",
        "入力文の各部分の重要度を判断し、関連性の高い情報に注目する仕組み",
        "AIが疲れないように休憩を入れる機能",
        "長文を短く要約する機能"
      ],
      correctIndex: 1,
      explanation: "Attention機構は、入力テキストの各部分がどの程度関連しているかを計算し、重要な情報に注目して処理する仕組みです。これにより長文でも文脈を正確に理解できます。お客様には「人間が文章を読むとき重要な部分に注目するのと同じ原理」と説明できます。"
    },
    {
      id: "llm-010",
      question: "「ベクトル」とはLLMにおいて何を表しますか？",
      options: [
        "AIの移動方向",
        "単語や文章を数値の配列として表現したもの",
        "ウイルス対策機能",
        "グラフィック画像の種類"
      ],
      correctIndex: 1,
      explanation: "ベクトルは、単語や文章の意味を数百〜数千次元の数値配列として表現したものです。意味の近い言葉は近いベクトルになります。営業では「AIは言葉を数値に変換して計算している」と説明することで、なぜ類似検索やRAGが可能かを説明できます。"
    },
    {
      id: "llm-011",
      question: "「エンベディング（Embedding）」とは何ですか？",
      options: [
        "AIをシステムに組み込むこと",
        "テキストを意味を保持した数値ベクトルに変換すること",
        "画像をテキストに変換すること",
        "データを圧縮すること"
      ],
      correctIndex: 1,
      explanation: "エンベディングは、テキストをその意味を表す数値ベクトルに変換する技術です。RAG（検索拡張生成）やセマンティック検索の基盤技術です。お客様には「似た意味の文章を探し出す技術の基盤」と説明し、社内文書検索などの活用例を提案できます。"
    },
    {
      id: "llm-012",
      question: "LLMの「学習データ」に関する説明として正しいものはどれですか？",
      options: [
        "ユーザーとの会話は全て学習データとして使用される",
        "インターネット上の書籍、ウェブサイト、論文などの大量のテキストが使用される",
        "学習データは完全に公開されている",
        "学習データは常にリアルタイムで更新される"
      ],
      correctIndex: 1,
      explanation: "LLMは主にインターネット上の公開テキストデータで学習されています。ただし、具体的なデータセットは各社で異なり、ユーザーの会話データの扱いも利用規約によって異なります。お客様のデータプライバシーへの懸念には、各サービスの利用規約を確認することを勧めましょう。"
    },
    {
      id: "llm-013",
      question: "「知識のカットオフ」とは何を意味しますか？",
      options: [
        "AIの知識を制限すること",
        "学習データの収集が終了した時点以降の情報をAIが持っていないこと",
        "ユーザーの質問を途中で打ち切ること",
        "AIの利用時間制限"
      ],
      correctIndex: 1,
      explanation: "知識のカットオフは、LLMの学習データ収集が終了した日付を指します。例えば2023年4月がカットオフの場合、それ以降のニュースや出来事については回答できません。営業では「最新情報にはRAGやウェブ検索機能の併用が有効」と提案できます。"
    },
    {
      id: "llm-014",
      question: "LLMの「レイテンシー」とは何を指しますか？",
      options: [
        "AIの学習にかかる時間",
        "ユーザーの入力から回答が返ってくるまでの待ち時間",
        "AIの利用可能時間",
        "契約期間"
      ],
      correctIndex: 1,
      explanation: "レイテンシーは、質問を送信してから回答が返ってくるまでの応答時間です。リアルタイム性が求められるチャットボットでは重要な指標です。営業では「平均応答時間は○秒程度」と具体的な数値を示すと説得力が増します。"
    },
    {
      id: "llm-015",
      question: "「スループット」とは何を指しますか？",
      options: [
        "AIの精度",
        "単位時間あたりに処理できるリクエスト数やトークン数",
        "AIの学習速度",
        "ユーザー満足度"
      ],
      correctIndex: 1,
      explanation: "スループットは、LLMが単位時間あたりに処理できるリクエスト数やトークン数を表します。大量のリクエストを処理する業務では重要な指標です。お客様の利用規模を確認し、必要なスループットを満たすプランを提案しましょう。"
    },
    {
      id: "llm-016",
      question: "「入力トークン」と「出力トークン」の違いは何ですか？",
      options: [
        "違いはなく同じものを指す",
        "入力トークンはユーザーの質問、出力トークンはAIの回答の長さを表す",
        "入力トークンは暗号化前、出力トークンは暗号化後のデータ",
        "入力トークンはAPIキー、出力トークンはアクセストークン"
      ],
      correctIndex: 1,
      explanation: "入力トークンはユーザーがAIに送信するテキストの量、出力トークンはAIが生成する回答の量を表します。多くのAPIでは両方に対して課金され、出力トークンの方が高額な場合が多いです。コスト見積もりでは両方を考慮しましょう。"
    },
    {
      id: "llm-017",
      question: "LLMの「ファインチューニング」と「プロンプトエンジニアリング」の違いは何ですか？",
      options: [
        "同じことを指す別の言い方",
        "ファインチューニングはモデル自体を再学習、プロンプトは入力文の工夫",
        "ファインチューニングは無料、プロンプトは有料",
        "ファインチューニングはAPI、プロンプトはUI"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは特定のデータでモデル自体を追加学習させる手法で、コストと時間がかかります。プロンプトエンジニアリングは入力文の工夫で望む出力を得る手法で、手軽に始められます。まずはプロンプトの工夫から始め、必要に応じてファインチューニングを提案しましょう。"
    },
    {
      id: "llm-018",
      question: "「ゼロショット学習」とは何ですか？",
      options: [
        "学習なしでAIを使うこと",
        "例を示さずに指示だけでタスクを実行させること",
        "無料でAIを使うこと",
        "エラーなしで処理すること"
      ],
      correctIndex: 1,
      explanation: "ゼロショット学習は、具体的な例を示さずに指示文だけでLLMにタスクを実行させることです。LLMは事前学習で獲得した知識を活用して対応します。営業では「追加の学習データなしで様々なタスクに対応できる」という利点として説明できます。"
    },
    {
      id: "llm-019",
      question: "「フューショット学習」とは何ですか？",
      options: [
        "少ない計算で学習すること",
        "プロンプト内に数個の例を示してタスクを実行させること",
        "撮影しながら学習すること",
        "短時間で学習を完了すること"
      ],
      correctIndex: 1,
      explanation: "フューショット学習は、プロンプト内に数個の入出力例を示すことで、LLMにタスクの期待する形式や内容を理解させる手法です。お客様の業務に合わせた例を用意することで、精度を大幅に向上させられます。導入支援時の具体的なテクニックとして提案しましょう。"
    },
    {
      id: "llm-020",
      question: "LLMにおける「トークナイザー」の役割は何ですか？",
      options: [
        "料金を計算するプログラム",
        "テキストをトークンに分割するプログラム",
        "ユーザー認証を行うプログラム",
        "データを暗号化するプログラム"
      ],
      correctIndex: 1,
      explanation: "トークナイザーは、入力テキストをLLMが処理できるトークンに分割するプログラムです。モデルごとにトークナイザーが異なるため、同じ文章でもトークン数が変わることがあります。料金計算の際は、使用するモデルのトークナイザーで確認することを勧めましょう。"
    },

    // === 主要なLLMサービス（21-40） ===
    {
      id: "llm-021",
      question: "ChatGPTを開発した企業はどこですか？",
      options: [
        "Google",
        "Microsoft",
        "OpenAI",
        "Meta"
      ],
      correctIndex: 2,
      explanation: "ChatGPTはOpenAIが開発しました。MicrosoftはOpenAIに大規模投資を行っており、Azure OpenAI ServiceとしてChatGPTの技術を提供しています。競合他社の関係性を理解しておくと、お客様の既存環境に合わせた提案ができます。"
    },
    {
      id: "llm-022",
      question: "Claudeを開発した企業はどこですか？",
      options: [
        "OpenAI",
        "Anthropic",
        "Google",
        "Amazon"
      ],
      correctIndex: 1,
      explanation: "ClaudeはAnthropicが開発しました。AnthropicはOpenAIの元メンバーが設立した企業で、AIの安全性研究に力を入れています。Amazon Web Services（AWS）と提携しており、AWS経由での利用も可能です。お客様のクラウド環境に応じた提案が可能です。"
    },
    {
      id: "llm-023",
      question: "GeminiはどのIT企業が開発したLLMですか？",
      options: [
        "Microsoft",
        "Google",
        "Apple",
        "OpenAI"
      ],
      correctIndex: 1,
      explanation: "GeminiはGoogleが開発したLLMで、Google WorkspaceやGoogle Cloudとの連携が強みです。既にGoogleのサービスを利用しているお客様には、Geminiの導入がスムーズになる可能性があることを提案できます。"
    },
    {
      id: "llm-024",
      question: "LLaMA（ラマ）を開発した企業はどこですか？",
      options: [
        "OpenAI",
        "Google",
        "Meta（旧Facebook）",
        "Microsoft"
      ],
      correctIndex: 2,
      explanation: "LLaMAはMeta（旧Facebook）が開発したオープンソースのLLMです。研究目的で公開され、多くの派生モデルが生まれました。オープンソースモデルを自社サーバーで運用したいお客様には、LLaMAベースのソリューションを検討できます。"
    },
    {
      id: "llm-025",
      question: "GPT-4とGPT-3.5の主な違いは何ですか？",
      options: [
        "GPT-4の方が安い",
        "GPT-4は推論能力が高く、より複雑なタスクに対応できる",
        "GPT-3.5の方が新しい",
        "GPT-4は英語のみ対応"
      ],
      correctIndex: 1,
      explanation: "GPT-4はGPT-3.5より推論能力、正確性、安全性が向上しており、より複雑なタスクに対応できます。ただし料金も高くなります。営業では、お客様の要件と予算に応じてモデルを使い分ける提案が有効です。シンプルなタスクにはGPT-3.5で十分な場合もあります。"
    },
    {
      id: "llm-026",
      question: "Azure OpenAI Serviceの特徴として正しいものはどれですか？",
      options: [
        "OpenAIより安い料金でGPTモデルを使える",
        "Microsoftのエンタープライズ向けセキュリティ基準を満たす環境でGPTを利用できる",
        "GPTより高性能な独自モデルを使える",
        "無料で利用できる"
      ],
      correctIndex: 1,
      explanation: "Azure OpenAI Serviceは、MicrosoftのAzure上でGPTモデルを利用できるサービスです。エンタープライズ向けのセキュリティ、コンプライアンス基準を満たし、既存のAzure環境と統合できます。セキュリティ要件の厳しい企業には特に有効な選択肢として提案できます。"
    },
    {
      id: "llm-027",
      question: "Amazon Bedrockとは何ですか？",
      options: [
        "Amazonが開発したLLM",
        "AWS上で複数のLLMを選択・利用できるマネージドサービス",
        "Amazonの商品推薦AI",
        "AWSのサーバーハードウェア"
      ],
      correctIndex: 1,
      explanation: "Amazon Bedrockは、Claude、Titan、LLaMAなど複数のLLMをAWS上で選択・利用できるマネージドサービスです。既にAWSを利用しているお客様には、既存環境との統合が容易であることを強調できます。"
    },
    {
      id: "llm-028",
      question: "Google Vertex AIの特徴は何ですか？",
      options: [
        "無料のLLMサービス",
        "Googleの機械学習プラットフォームでGeminiなどを利用・カスタマイズできる",
        "ゲーム専用のAIサービス",
        "個人向けの簡易AIツール"
      ],
      correctIndex: 1,
      explanation: "Vertex AIはGoogleの機械学習プラットフォームで、Geminiなどのモデルを利用・カスタマイズできます。Google Cloudの他のサービスとの連携も容易です。BigQueryなどを活用している企業には、データ連携の観点から提案できます。"
    },
    {
      id: "llm-029",
      question: "「オープンソースLLM」の利点として正しいものはどれですか？",
      options: [
        "必ず商用利用が無料",
        "自社環境でモデルを運用でき、データを外部に送信せずに済む",
        "常にプロプライエタリモデルより高性能",
        "サポートが手厚い"
      ],
      correctIndex: 1,
      explanation: "オープンソースLLMは、自社サーバーやプライベートクラウドで運用できるため、機密データを外部に送信する必要がありません。ただし、運用には技術力が必要です。データセキュリティ要件の厳しいお客様には、オンプレミス運用の選択肢として提案できます。"
    },
    {
      id: "llm-030",
      question: "Mistral AIはどの国発のLLMスタートアップですか？",
      options: [
        "アメリカ",
        "中国",
        "フランス",
        "日本"
      ],
      correctIndex: 2,
      explanation: "Mistral AIはフランスのパリを拠点とするスタートアップで、高性能かつオープンなLLMを開発しています。EUのデータ規制対応を重視するお客様には、欧州発のAI企業として選択肢になります。"
    },
    {
      id: "llm-031",
      question: "「GPT」とは何の略ですか？",
      options: [
        "General Purpose Technology",
        "Generative Pre-trained Transformer",
        "Global Processing Tool",
        "Graphical Programming Terminal"
      ],
      correctIndex: 1,
      explanation: "GPTは「Generative Pre-trained Transformer（生成的事前学習Transformer）」の略です。名前の通り、事前学習されたTransformerベースのテキスト生成モデルです。お客様に「GPTとは何か」と聞かれた際に、正式名称と意味を説明できると信頼感が増します。"
    },
    {
      id: "llm-032",
      question: "ChatGPT Plusの主な特徴は何ですか？",
      options: [
        "完全無料で使える",
        "月額課金でGPT-4やDALL-Eなどの機能にアクセスできる",
        "企業専用のサービス",
        "オフラインで使える"
      ],
      correctIndex: 1,
      explanation: "ChatGPT Plusは月額課金の個人向けプランで、GPT-4、画像生成（DALL-E）、コード実行などの高度な機能を利用できます。無料版との違いを説明し、お客様の利用目的に応じて適切なプランを提案しましょう。企業利用にはEnterprise版もあります。"
    },
    {
      id: "llm-033",
      question: "Claude 3のモデルシリーズ「Opus」「Sonnet」「Haiku」の違いは何ですか？",
      options: [
        "対応言語の違い",
        "性能と価格のバランスの違い（Opusが最高性能、Haikuが最軽量）",
        "開発された年の違い",
        "利用できる地域の違い"
      ],
      correctIndex: 1,
      explanation: "Claude 3シリーズはOpus（最高性能）、Sonnet（バランス型）、Haiku（軽量・高速・低コスト）の3つがあります。お客様のユースケースに応じて、「複雑な分析はOpus、日常的なタスクはHaiku」といった使い分けを提案できます。"
    },
    {
      id: "llm-034",
      question: "「Copilot」とはMicrosoftのどのようなサービスですか？",
      options: [
        "航空機の自動操縦システム",
        "AIアシスタントで、Office製品やWindowsに統合されている",
        "プログラミング言語",
        "クラウドストレージサービス"
      ],
      correctIndex: 1,
      explanation: "Microsoft CopilotはGPT技術を活用したAIアシスタントで、Word、Excel、Teams、Windowsなどに統合されています。既存のMicrosoft 365ユーザーには、普段の業務ツールにAIが組み込まれる利便性を訴求できます。"
    },
    {
      id: "llm-035",
      question: "GitHub Copilotは何を支援するAIツールですか？",
      options: [
        "文書作成",
        "プログラミング・コード作成",
        "画像編集",
        "音声認識"
      ],
      correctIndex: 1,
      explanation: "GitHub CopilotはOpenAIの技術を活用したプログラミング支援AIで、コードの自動補完や提案を行います。開発チームを持つお客様には、開発生産性向上のソリューションとして提案できます。"
    },
    {
      id: "llm-036",
      question: "「ChatGPT Enterprise」の主な特徴は何ですか？",
      options: [
        "個人向けの無料サービス",
        "企業向けにセキュリティ強化・管理機能・無制限利用を提供",
        "教育機関専用のサービス",
        "研究者向けのAPIサービス"
      ],
      correctIndex: 1,
      explanation: "ChatGPT Enterpriseは企業向けプランで、SOC 2準拠のセキュリティ、管理コンソール、SSO対応、無制限のGPT-4利用などを提供します。大企業のセキュリティ要件やIT管理要件を満たす必要がある場合に提案できます。"
    },
    {
      id: "llm-037",
      question: "日本語に強いとされる国産LLMはどれですか？",
      options: [
        "GPT-4",
        "ELYZA、PLaMo、Japanese StableLMなど",
        "LLaMA",
        "PaLM"
      ],
      correctIndex: 1,
      explanation: "ELYZA（PKSHA/東京大学発）、PLaMo（Preferred Networks）、Japanese StableLM（Stability AI Japan）など、日本語に特化したLLMが開発されています。日本語特有のニュアンスや敬語表現を重視するお客様には、国産モデルの選択肢を提案できます。"
    },
    {
      id: "llm-038",
      question: "Perplexityとは何ですか？",
      options: [
        "LLMの評価指標",
        "AI検索エンジンで、情報源を明示しながら回答するサービス",
        "プログラミング言語",
        "データベース製品"
      ],
      correctIndex: 1,
      explanation: "Perplexityは、LLMを活用したAI検索エンジンで、ウェブ検索結果を元に回答し、情報源を明示します。最新情報へのアクセスとハルシネーション軽減が特徴です。「検索と要約を一度に行いたい」というお客様のニーズに応えられます。"
    },
    {
      id: "llm-039",
      question: "「GPT-4 Turbo」と「GPT-4」の主な違いは何ですか？",
      options: [
        "GPT-4 Turboの方が性能が低い",
        "GPT-4 Turboは知識が新しく、コンテキストウィンドウが大きく、料金が安い",
        "GPT-4 TurboはAPI非対応",
        "GPT-4 Turboは日本語非対応"
      ],
      correctIndex: 1,
      explanation: "GPT-4 Turboは、GPT-4より知識のカットオフが新しく、128Kトークンの大きなコンテキストウィンドウを持ち、料金も安くなっています。長文処理やコスト重視のお客様には、GPT-4 Turboを優先的に提案できます。"
    },
    {
      id: "llm-040",
      question: "「o1」（OpenAI o1）の特徴は何ですか？",
      options: [
        "画像生成に特化したモデル",
        "複雑な推論を得意とし、数学や科学の問題に強いモデル",
        "音声認識専用のモデル",
        "最も安価なモデル"
      ],
      correctIndex: 1,
      explanation: "OpenAI o1は「thinking（思考）」機能を持ち、複雑な推論、数学、科学、コーディングの問題で高い性能を発揮します。ただし応答時間が長く、料金も高いです。高度な分析や推論が必要なユースケースに提案できます。"
    },

    // === ハルシネーション、バイアス、安全性（41-55） ===
    {
      id: "llm-041",
      question: "LLMの「ハルシネーション」とは何を指しますか？",
      options: [
        "高速で文章を生成する機能",
        "事実と異なる情報をもっともらしく生成してしまう現象",
        "複数の言語を同時に処理する能力",
        "ユーザーの意図を正確に理解する機能"
      ],
      correctIndex: 1,
      explanation: "ハルシネーション（幻覚）とは、LLMが事実ではない情報をあたかも本当のことのように自信を持って回答してしまう現象です。営業活動では「AIの回答は必ず人間が確認する運用が重要」とお客様にアドバイスし、適切な期待値を設定しましょう。"
    },
    {
      id: "llm-042",
      question: "ハルシネーションを軽減する方法として最も効果的なものはどれですか？",
      options: [
        "より長い文章で質問する",
        "RAG（検索拡張生成）で外部知識を参照させる",
        "複数のユーザーで同じ質問をする",
        "AIに「正確に答えてください」と指示する"
      ],
      correctIndex: 1,
      explanation: "RAG（Retrieval-Augmented Generation）は、外部のデータベースや文書から関連情報を検索し、それを元に回答を生成する手法です。これによりハルシネーションを大幅に軽減できます。お客様には「御社の正確な情報に基づいて回答するシステム」として提案できます。"
    },
    {
      id: "llm-043",
      question: "LLMの「バイアス」問題とは何ですか？",
      options: [
        "電気的なノイズの問題",
        "学習データの偏りがAIの出力に反映され、不公平な結果を生む可能性",
        "AIの処理速度が遅くなる問題",
        "AIのコストが高くなる問題"
      ],
      correctIndex: 1,
      explanation: "LLMは学習データに含まれる社会的バイアス（性別、人種、文化的偏見など）を反映してしまう可能性があります。採用支援や審査業務などでAIを使う場合は、バイアスの検証と人間によるチェック体制の構築が重要です。"
    },
    {
      id: "llm-044",
      question: "「RLHF」とは何の略で、何を目的としていますか？",
      options: [
        "Real-time Language Helper Function - リアルタイム翻訳機能",
        "Reinforcement Learning from Human Feedback - 人間のフィードバックによる強化学習",
        "Rapid Learning for High Frequency - 高頻度データの高速学習",
        "Responsive Language Handling Framework - 応答性の高い言語処理フレームワーク"
      ],
      correctIndex: 1,
      explanation: "RLHFは「人間のフィードバックによる強化学習」の略で、人間の評価者がAIの回答を評価し、その結果をモデルの改善に活用する手法です。これにより、AIをより安全で有用なものにします。営業では「AIの安全性を高める最新技術を採用」と説明できます。"
    },
    {
      id: "llm-045",
      question: "LLMの「ジェイルブレイク」とは何ですか？",
      options: [
        "AIを脱獄させるゲーム",
        "安全対策を回避して有害な出力を引き出そうとする攻撃手法",
        "AIを刑務所で使うシステム",
        "AIの処理速度を上げるテクニック"
      ],
      correctIndex: 1,
      explanation: "ジェイルブレイクは、特殊なプロンプトでLLMの安全対策を回避し、通常は拒否される有害な出力を引き出そうとする攻撃手法です。お客様には「セキュリティ対策済みのエンタープライズ版の利用」や「出力のモニタリング体制」の重要性を説明しましょう。"
    },
    {
      id: "llm-046",
      question: "「コンテンツフィルタリング」とは何ですか？",
      options: [
        "AIの出力からファイルを抽出する機能",
        "有害・不適切なコンテンツの入出力を検知・ブロックする機能",
        "AIの回答を短くする機能",
        "著作権コンテンツを検出する機能"
      ],
      correctIndex: 1,
      explanation: "コンテンツフィルタリングは、暴力的、性的、違法な内容などの不適切なコンテンツの入出力を検知・ブロックする機能です。Azure OpenAI Serviceなどのエンタープライズサービスでは、この機能をカスタマイズできます。"
    },
    {
      id: "llm-047",
      question: "「プロンプトインジェクション」攻撃とは何ですか？",
      options: [
        "AIに大量のプロンプトを送る攻撃",
        "悪意ある指示を入力に紛れ込ませ、AIの動作を操作しようとする攻撃",
        "プロンプトを暗号化する攻撃",
        "AIのプロンプトを盗む攻撃"
      ],
      correctIndex: 1,
      explanation: "プロンプトインジェクションは、ユーザー入力に悪意ある指示を紛れ込ませ、システムプロンプトを無視させたり、意図しない動作をさせようとする攻撃です。AI搭載システムの開発では、入力の検証やサンドボックス化などの対策が必要です。"
    },
    {
      id: "llm-048",
      question: "LLMの「説明責任」として重要な考え方はどれですか？",
      options: [
        "AIの出力は常に正しいので説明不要",
        "AIの判断根拠を可能な限り明示し、人間が最終判断する体制を構築する",
        "AIの内部構造を全て公開する",
        "AIの利用を最小限にする"
      ],
      correctIndex: 1,
      explanation: "AIの説明責任では、なぜその出力に至ったかを説明でき、人間が最終的な判断と責任を持つ体制が重要です。特に重要な意思決定にAIを使う場合は、「AIは参考意見を提供し、人間が最終判断する」運用を提案しましょう。"
    },
    {
      id: "llm-049",
      question: "「Constitutional AI」とはAnthropicが提唱する何のアプローチですか？",
      options: [
        "憲法を学習させるAI",
        "AIに原則（憲法）を与え、自己批判・改善させる安全性向上手法",
        "政府機関専用のAI",
        "AIの法的権利に関する議論"
      ],
      correctIndex: 1,
      explanation: "Constitutional AIは、Anthropicが開発した手法で、AIに「有害な出力を避ける」などの原則を与え、自らの出力を批判・改善させます。これによりRLHFより効率的に安全なAIを構築できます。Claudeの安全性の技術的背景として説明できます。"
    },
    {
      id: "llm-050",
      question: "データプライバシーの観点で、LLM利用時に注意すべきことは何ですか？",
      options: [
        "LLMは全てのデータを自動的に暗号化するので心配不要",
        "機密情報や個人情報をプロンプトに含めない、または専用環境を使用する",
        "LLMには法的規制がないので自由に使える",
        "公開情報のみ学習しているので問題ない"
      ],
      correctIndex: 1,
      explanation: "LLMのAPIに送信したデータは、利用規約によってはモデル改善に使用される可能性があります。機密情報を扱う場合は、データが学習に使用されないプランや、オンプレミス環境の利用を検討しましょう。お客様のデータポリシーに合わせた提案が重要です。"
    },
    {
      id: "llm-051",
      question: "LLMが著作権侵害を引き起こす可能性があるケースはどれですか？",
      options: [
        "AIを使うこと自体が著作権侵害",
        "学習データに含まれるコンテンツを大量にそのまま出力する場合",
        "AIの回答を引用する場合",
        "AIに著作物について質問する場合"
      ],
      correctIndex: 1,
      explanation: "LLMが学習データに含まれる書籍や記事の内容をそのまま大量に出力する場合、著作権侵害の可能性があります。現在、各国で法整備が進行中です。お客様には「AI生成物の商用利用時は権利関係の確認が必要」とアドバイスしましょう。"
    },
    {
      id: "llm-052",
      question: "「AI幻覚」とも呼ばれるハルシネーションが特に問題になる業界はどれですか？",
      options: [
        "エンターテイメント業界",
        "医療・法律・金融など正確性が重要な業界",
        "農業業界",
        "運輸業界"
      ],
      correctIndex: 1,
      explanation: "医療診断、法律アドバイス、金融判断など、誤った情報が深刻な被害につながる分野では、ハルシネーションは特に問題です。これらの業界では「AIは補助ツールとして使用し、専門家が必ず確認する」運用を強く推奨しましょう。"
    },
    {
      id: "llm-053",
      question: "LLMの安全性向上のための「レッドチーミング」とは何ですか？",
      options: [
        "赤いチームカラーで開発すること",
        "意図的に攻撃や悪用を試みて脆弱性を発見するテスト",
        "緊急時対応チームのこと",
        "セキュリティソフトの名前"
      ],
      correctIndex: 1,
      explanation: "レッドチーミングは、専門家が意図的にAIシステムを攻撃・悪用しようとして、脆弱性や問題点を発見するセキュリティテスト手法です。主要なLLM開発企業はリリース前にレッドチーミングを実施しています。セキュリティに敏感なお客様への説明に活用できます。"
    },
    {
      id: "llm-054",
      question: "「モデルカード」とは何ですか？",
      options: [
        "AIモデルのクレジットカード",
        "AIモデルの性能、限界、倫理的考慮事項などを記載した文書",
        "AIモデルの名刺",
        "AIモデルの保証書"
      ],
      correctIndex: 1,
      explanation: "モデルカードは、AIモデルの性能評価、適切な使用例、限界、バイアスの可能性、倫理的考慮事項などを記載した文書です。責任あるAI開発の一環として公開されます。お客様にAIの限界を説明する際の参考資料として活用できます。"
    },
    {
      id: "llm-055",
      question: "EU AI Act（EU人工知能規則）でLLMはどのように扱われる予定ですか？",
      options: [
        "全面禁止",
        "汎用AIシステムとして透明性要件などの規制対象",
        "規制対象外",
        "医療用途のみ規制対象"
      ],
      correctIndex: 1,
      explanation: "EU AI Actでは、LLMなどの汎用AIシステムは透明性要件（技術文書の作成、EU法への準拠など）が課されます。高リスク用途ではさらに厳しい要件があります。EUでビジネスを行うお客様には、コンプライアンス対応の必要性を説明しましょう。"
    },

    // === 料金体系、API、利用制限（56-70） ===
    {
      id: "llm-056",
      question: "多くのLLM APIの料金体系はどのようになっていますか？",
      options: [
        "月額固定料金のみ",
        "処理したトークン数に応じた従量課金",
        "1回の質問ごとの固定料金",
        "ユーザー数に応じた料金"
      ],
      correctIndex: 1,
      explanation: "多くのLLM APIは、入力トークン数と出力トークン数に応じた従量課金制です。通常、1,000トークンあたりの単価で計算されます。お客様の予想利用量から月額費用を見積もり、予算に合った提案をしましょう。"
    },
    {
      id: "llm-057",
      question: "「RPM」と「TPM」とは何を指しますか？",
      options: [
        "回転数と温度の測定単位",
        "1分あたりのリクエスト数（RPM）とトークン数（TPM）の制限",
        "収益とコストの指標",
        "品質管理の基準"
      ],
      correctIndex: 1,
      explanation: "RPM（Requests Per Minute）は1分あたりのAPI呼び出し回数制限、TPM（Tokens Per Minute）は1分あたりの処理トークン数制限です。これらの制限を超えるとエラーになります。お客様の想定利用量に応じて、適切なプラン選択や制限緩和を提案しましょう。"
    },
    {
      id: "llm-058",
      question: "OpenAI APIの「Tier」とは何を指しますか？",
      options: [
        "AIの性能ランク",
        "利用金額に応じた利用制限の緩和レベル",
        "料金の割引率",
        "データセンターの階層"
      ],
      correctIndex: 1,
      explanation: "OpenAI APIのTierは、過去の利用金額や支払い実績に応じて設定される利用制限のレベルです。Tierが上がると、RPMやTPMの制限が緩和されます。利用量の多いお客様には、Tier昇格のプロセスを説明し、将来の拡張に備えた計画を提案しましょう。"
    },
    {
      id: "llm-059",
      question: "「ストリーミングレスポンス」とは何ですか？",
      options: [
        "動画を生成する機能",
        "回答を一度に返すのではなく、生成しながら少しずつ返す方式",
        "音楽ストリーミングサービスとの連携",
        "データをリアルタイムで分析する機能"
      ],
      correctIndex: 1,
      explanation: "ストリーミングレスポンスは、LLMの回答を生成しながら少しずつ返す方式です。ユーザーは回答全体の生成を待たずに読み始められるため、体感待ち時間を短縮できます。チャットボット開発では標準的に採用される方式です。"
    },
    {
      id: "llm-060",
      question: "「APIキー」の管理で最も重要な注意点は何ですか？",
      options: [
        "キーは定期的に変更する必要はない",
        "キーを公開リポジトリやフロントエンドコードに含めない",
        "キーは複数人で共有すると便利",
        "キーは長いほど安全"
      ],
      correctIndex: 1,
      explanation: "APIキーは機密情報であり、GitHubなどの公開リポジトリやフロントエンドのJavaScriptコードに含めると漏洩の危険があります。漏洩すると第三者に悪用され、高額な請求が発生する可能性があります。環境変数やシークレット管理サービスの利用を推奨しましょう。"
    },
    {
      id: "llm-061",
      question: "「バッチAPI」の利点は何ですか？",
      options: [
        "リアルタイム応答が速くなる",
        "大量のリクエストを非同期でまとめて処理でき、料金が割安になることが多い",
        "画像を一括処理できる",
        "複数のモデルを同時に使える"
      ],
      correctIndex: 1,
      explanation: "バッチAPIは、大量のリクエストを非同期でまとめて処理する方式で、通常のAPIより料金が割安になることが多いです（OpenAIでは50%オフ）。即座の応答が不要な大量処理（文書の一括分析など）に適しており、コスト最適化の提案に活用できます。"
    },
    {
      id: "llm-062",
      question: "「Fine-tuning API」の料金はどのように発生しますか？",
      options: [
        "学習時のみ料金が発生",
        "学習時の料金と、ファインチューニングモデル使用時の推論料金の両方が発生",
        "推論時のみ料金が発生",
        "完全に無料"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングでは、学習データの処理に対する料金と、学習済みモデルを使用する際の推論料金（通常より高い場合が多い）の両方が発生します。総コストを見積もる際は、学習コストと継続的な利用コストの両方を考慮しましょう。"
    },
    {
      id: "llm-063",
      question: "「キャッシング」によるLLMコスト削減の仕組みはどれですか？",
      options: [
        "現金で支払うと割引される",
        "同じ質問への回答を保存し、再度同じ質問が来たらAPIを呼ばずに返す",
        "複数の契約をまとめることで割引される",
        "使用していない期間の料金が免除される"
      ],
      correctIndex: 1,
      explanation: "キャッシングは、過去の質問と回答を保存し、同じ質問が来た場合にAPIを呼び出さずに保存済みの回答を返す仕組みです。FAQボットなど同じ質問が多いユースケースでは、大幅なコスト削減が可能です。"
    },
    {
      id: "llm-064",
      question: "「Embedding API」と「Chat API」の料金を比較すると一般的にどちらが高いですか？",
      options: [
        "Embedding APIの方が大幅に高い",
        "Chat API（生成API）の方が高い",
        "料金は同じ",
        "利用量によって逆転する"
      ],
      correctIndex: 1,
      explanation: "一般的に、テキスト生成を行うChat APIの方が、ベクトル変換のみを行うEmbedding APIより料金が高いです。RAGシステムでは、検索（Embedding）と生成（Chat）でAPIを使い分けることで、コスト効率の良いシステムを構築できます。"
    },
    {
      id: "llm-065",
      question: "「レート制限エラー」が発生した場合の適切な対処法は何ですか？",
      options: [
        "すぐに同じリクエストを再送する",
        "指数バックオフ（徐々に待ち時間を延ばして再試行）を実装する",
        "APIキーを変更する",
        "別のモデルに切り替える"
      ],
      correctIndex: 1,
      explanation: "レート制限エラー（429エラー）が発生した場合は、指数バックオフ（1秒、2秒、4秒...と待ち時間を延ばしながら再試行）を実装するのが一般的です。すぐに再送すると制限が続くため逆効果です。開発チームには適切なエラーハンドリングの実装を推奨しましょう。"
    },
    {
      id: "llm-066",
      question: "「SLA（Service Level Agreement）」でLLM APIにおいて保証される主な項目は何ですか？",
      options: [
        "AIの回答精度",
        "稼働率（アップタイム）やレスポンス時間",
        "ハルシネーションの発生率",
        "トレーニングの効果"
      ],
      correctIndex: 1,
      explanation: "LLM APIのSLAでは主に稼働率（例：99.9%）やサポート対応時間などが保証されます。回答精度やハルシネーション率は保証対象外です。エンタープライズ契約では、お客様の業務要件に合うSLAを確認しましょう。"
    },
    {
      id: "llm-067",
      question: "OpenAI APIの「Assistants API」とは何ですか？",
      options: [
        "人間のアシスタントを手配するサービス",
        "会話の継続、ファイル処理、ツール実行などの機能を備えたAIアシスタント構築API",
        "音声アシスタント専用のAPI",
        "カスタマーサポート用の電話API"
      ],
      correctIndex: 1,
      explanation: "Assistants APIは、会話履歴の管理、ファイルのアップロード・検索、コード実行、関数呼び出しなどの機能を統合的に提供するAPIです。複雑なAIアシスタントを構築する際に、これらの機能を自前で実装する手間を省けます。"
    },
    {
      id: "llm-068",
      question: "「Function Calling」機能とは何ですか？",
      options: [
        "電話をかける機能",
        "LLMが外部の関数やAPIを呼び出すタイミングと引数を判断する機能",
        "関数型プログラミングでAIを開発する方式",
        "AIが数学の関数を計算する機能"
      ],
      correctIndex: 1,
      explanation: "Function Calling（関数呼び出し）は、LLMがユーザーの質問に基づいて、どの外部関数を呼ぶべきか、どんな引数を渡すべきかを判断する機能です。これにより、予約システムやデータベース検索など外部システムとの連携が容易になります。"
    },
    {
      id: "llm-069",
      question: "「JSON Mode」とは何ですか？",
      options: [
        "JSONファイルを読み込むモード",
        "LLMの出力を必ずJSON形式にする設定",
        "データベース接続モード",
        "JavaScript専用のAPI"
      ],
      correctIndex: 1,
      explanation: "JSON Modeは、LLMの出力を必ず有効なJSON形式にする設定です。APIレスポンスをプログラムで処理する際に、パースエラーを防げます。システム連携やデータ抽出タスクでは必須の設定として推奨しましょう。"
    },
    {
      id: "llm-070",
      question: "「コスト上限設定」の重要性として正しいものはどれですか？",
      options: [
        "設定しなくても問題ない",
        "予期せぬ大量利用による高額請求を防ぐために重要",
        "設定すると性能が下がる",
        "エンタープライズプランでは不要"
      ],
      correctIndex: 1,
      explanation: "コスト上限設定は、プログラムのバグや予期せぬ大量アクセスによる高額請求を防ぐ安全装置です。開発段階や本番環境でも必ず設定することを推奨しましょう。過去に設定なしで数百万円の請求が発生した事例もあります。"
    },

    // === プロンプトの基本（71-82） ===
    {
      id: "llm-071",
      question: "「プロンプト」とは何ですか？",
      options: [
        "AIの応答時間",
        "LLMに対する入力文（指示や質問）",
        "AIの性能指標",
        "AIのエラーメッセージ"
      ],
      correctIndex: 1,
      explanation: "プロンプトは、LLMに対して送る入力文のことで、質問、指示、文脈情報などを含みます。プロンプトの書き方次第で回答の質が大きく変わるため、プロンプトエンジニアリングというスキルが重要になっています。"
    },
    {
      id: "llm-072",
      question: "「システムプロンプト」の役割は何ですか？",
      options: [
        "システムエラーを報告するプロンプト",
        "AIの役割や振る舞いのルールを設定するプロンプト",
        "OSを起動するコマンド",
        "管理者用の特別なプロンプト"
      ],
      correctIndex: 1,
      explanation: "システムプロンプトは、AIに「あなたは〇〇の専門家です」「丁寧な敬語で回答してください」といった役割や振る舞いのルールを設定するプロンプトです。一貫した応答を得るための基盤となり、チャットボット開発で重要な役割を果たします。"
    },
    {
      id: "llm-073",
      question: "効果的なプロンプトの書き方として正しいものはどれですか？",
      options: [
        "できるだけ短く曖昧に書く",
        "具体的な指示、期待する出力形式、必要な文脈を明確に記述する",
        "専門用語をできるだけ多く使う",
        "感情的な表現を多用する"
      ],
      correctIndex: 1,
      explanation: "効果的なプロンプトは、具体的な指示、期待する出力形式（例：箇条書き、JSON形式）、必要な背景情報を明確に含みます。「分かりやすく説明して」より「初心者向けに3つのポイントで説明して」の方が良い結果が得られます。"
    },
    {
      id: "llm-074",
      question: "「Chain of Thought（思考の連鎖）」プロンプティングとは何ですか？",
      options: [
        "複数のAIを連結させる手法",
        "AIに段階的に考えさせることで推論精度を向上させる手法",
        "連続して質問を送る手法",
        "AIの思考を視覚化する手法"
      ],
      correctIndex: 1,
      explanation: "Chain of Thought（CoT）は、「ステップバイステップで考えてください」などの指示により、AIに推論過程を明示させる手法です。数学問題や論理的推論タスクで精度が向上します。複雑な分析タスクでは「まず〇〇を分析し、次に△△を検討してください」と段階を指定しましょう。"
    },
    {
      id: "llm-075",
      question: "「ロールプレイ」プロンプティングの効果は何ですか？",
      options: [
        "ゲームをプレイさせる",
        "AIに特定の役割や専門家を演じさせることで、その視点からの回答を得る",
        "ユーザーに役割を割り当てる",
        "AIの演技力を評価する"
      ],
      correctIndex: 1,
      explanation: "「あなたは10年経験のあるマーケティング専門家です」のように役割を与えると、AIはその視点から回答します。お客様の業界や用途に合わせた専門家ロールを設定することで、より適切な回答を得られます。"
    },
    {
      id: "llm-076",
      question: "「制約条件」をプロンプトに含める効果は何ですか？",
      options: [
        "AIの性能が下がる",
        "出力の形式や内容を制御し、用途に適した回答を得られる",
        "処理速度が上がる",
        "料金が安くなる"
      ],
      correctIndex: 1,
      explanation: "「100文字以内で」「専門用語を使わずに」「箇条書きで3点」などの制約条件を含めると、AIの出力を制御できます。業務用途では、出力形式を統一することでシステム連携や品質管理が容易になります。"
    },
    {
      id: "llm-077",
      question: "「プロンプトテンプレート」を使用する利点は何ですか？",
      options: [
        "処理速度が向上する",
        "一貫した品質の出力を得られ、プロンプト作成の効率も上がる",
        "料金が割引される",
        "AIの学習に使用される"
      ],
      correctIndex: 1,
      explanation: "プロンプトテンプレートは、変数部分（顧客名、製品名など）を埋め込むだけで使えるプロンプトの雛形です。チーム全体で品質を統一でき、作成効率も上がります。お客様には「御社専用のプロンプトテンプレート集」の作成を提案できます。"
    },
    {
      id: "llm-078",
      question: "「ネガティブプロンプト」とは何ですか？",
      options: [
        "否定的な質問をすること",
        "AIに「してほしくないこと」を明示的に指示すること",
        "AIを批判するプロンプト",
        "エラーを発生させるプロンプト"
      ],
      correctIndex: 1,
      explanation: "ネガティブプロンプトは、「〜しないでください」「〜を含めないでください」のように、AIに避けてほしい行動を明示する指示です。画像生成AIでは「不要な要素の除外」、テキスト生成では「専門用語を使わない」などに活用されます。"
    },
    {
      id: "llm-079",
      question: "「プロンプトチェーン」とは何ですか？",
      options: [
        "プロンプトを暗号化すること",
        "複数のプロンプトを連続して実行し、前の出力を次の入力に使う手法",
        "プロンプトをブロックチェーンに記録すること",
        "複数のAIを同時に使うこと"
      ],
      correctIndex: 1,
      explanation: "プロンプトチェーンは、「まず要約を作成」→「要約を元に質問を生成」→「質問に回答」のように、複数のプロンプトを連続して実行する手法です。複雑なタスクを分解して精度を向上させられます。"
    },
    {
      id: "llm-080",
      question: "プロンプトの「デリミター」とは何ですか？",
      options: [
        "プロンプトを削除するコマンド",
        "プロンプト内の異なるセクションを区切る記号（```、###など）",
        "プロンプトの長さ制限",
        "プロンプトの暗号化キー"
      ],
      correctIndex: 1,
      explanation: "デリミターは、プロンプト内で指示文、入力データ、例などを明確に区切る記号です。「###指示###」「```入力データ```」のように使用します。これにより、AIがプロンプトの構造を正確に理解しやすくなります。"
    },
    {
      id: "llm-081",
      question: "「プロンプトの最適化」で重要なアプローチは何ですか？",
      options: [
        "一度作成したら変更しない",
        "A/Bテストで複数のプロンプトを比較し、継続的に改善する",
        "できるだけ長いプロンプトを使う",
        "英語のプロンプトのみ使用する"
      ],
      correctIndex: 1,
      explanation: "プロンプトの最適化では、複数のバリエーションを作成してA/Bテストで効果を比較し、継続的に改善することが重要です。同じタスクでも、プロンプトの書き方次第で精度が大きく変わるため、本番運用前に十分なテストを行いましょう。"
    },
    {
      id: "llm-082",
      question: "「プロンプトエンジニアリング」が営業で重要な理由は何ですか？",
      options: [
        "プログラミングスキルの代わりになるから",
        "適切なプロンプト設計により、追加開発なしでAIの効果を最大化できるから",
        "プロンプトエンジニアを雇う必要がなくなるから",
        "AIの料金を無料にできるから"
      ],
      correctIndex: 1,
      explanation: "プロンプトエンジニアリングは、ファインチューニングなどの追加開発なしで、プロンプトの工夫だけでAIの効果を大幅に向上させられる手法です。導入コストを抑えつつ効果を出したいお客様には、プロンプト設計支援をセットで提案しましょう。"
    },

    // === ファインチューニング、RAG（83-92） ===
    {
      id: "llm-083",
      question: "「ファインチューニング」とは何ですか？",
      options: [
        "AIの音質を調整すること",
        "事前学習済みモデルを特定のデータで追加学習させること",
        "AIの料金を調整すること",
        "プロンプトを最適化すること"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは、事前学習済みのLLMを、お客様固有のデータや用途に合わせて追加学習させることです。独自の文体、専門知識、特定のタスクへの対応力を向上させられます。ただし、コストと効果のバランスを検討する必要があります。"
    },
    {
      id: "llm-084",
      question: "ファインチューニングが特に有効なケースはどれですか？",
      options: [
        "一般的な質問応答",
        "独自の文体やフォーマットで一貫した出力が必要な場合",
        "最新ニュースについての質問",
        "単純な翻訳タスク"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは、特定の文体（例：企業のトーン&マナー）、独自のフォーマット、専門用語の正確な使用が必要な場合に効果的です。お客様のブランドガイドラインに沿った文章生成などに活用できます。"
    },
    {
      id: "llm-085",
      question: "「RAG（Retrieval-Augmented Generation）」とは何ですか？",
      options: [
        "AIの一種のブランド名",
        "外部データベースから関連情報を検索し、それを元に回答を生成する手法",
        "AIの学習速度を上げる技術",
        "画像を生成する技術"
      ],
      correctIndex: 1,
      explanation: "RAG（検索拡張生成）は、質問に関連する情報を外部データベースや文書から検索し、その情報をコンテキストとしてLLMに渡すことで、正確で最新の情報に基づいた回答を生成する手法です。社内文書を活用したAIチャットボットの基盤技術として提案できます。"
    },
    {
      id: "llm-086",
      question: "RAGとファインチューニングの使い分けとして適切なものはどれですか？",
      options: [
        "どちらも同じ効果なので好みで選ぶ",
        "最新情報や頻繁に更新される情報にはRAG、一貫した文体やフォーマットにはファインチューニング",
        "RAGは高額、ファインチューニングは低額",
        "RAGは英語専用、ファインチューニングは日本語専用"
      ],
      correctIndex: 1,
      explanation: "RAGは外部データを参照するため最新情報への対応や頻繁な更新に強く、ファインチューニングはモデル自体の振る舞いを変えるため一貫した文体やフォーマットの実現に適しています。お客様の要件に応じて、どちらか、または両方の組み合わせを提案しましょう。"
    },
    {
      id: "llm-087",
      question: "RAGシステムで使用される「ベクトルデータベース」の役割は何ですか？",
      options: [
        "画像を保存するデータベース",
        "テキストのベクトル（埋め込み）を保存し、類似度検索を高速に行う",
        "AIのパラメータを保存するデータベース",
        "ユーザー情報を管理するデータベース"
      ],
      correctIndex: 1,
      explanation: "ベクトルデータベース（Pinecone、Weaviate、Chromaなど）は、テキストを変換した高次元ベクトルを保存し、質問ベクトルと類似した文書を高速に検索します。RAGシステムの「検索」部分を担う重要なコンポーネントです。"
    },
    {
      id: "llm-088",
      question: "RAGシステムの「チャンク」とは何ですか？",
      options: [
        "データの塊・断片のことで、長文を検索しやすいサイズに分割したもの",
        "エラーメッセージ",
        "APIリクエストの単位",
        "料金計算の単位"
      ],
      correctIndex: 0,
      explanation: "チャンクは、長い文書を検索に適したサイズに分割した断片です。チャンクサイズの設計は検索精度に大きく影響し、小さすぎると文脈が失われ、大きすぎると関連性の低い情報が含まれます。RAGシステム構築では重要な設計ポイントです。"
    },
    {
      id: "llm-089",
      question: "「LoRA（Low-Rank Adaptation）」とは何ですか？",
      options: [
        "低性能なAI",
        "少ないパラメータで効率的にファインチューニングを行う手法",
        "AIの音声処理技術",
        "低解像度の画像生成"
      ],
      correctIndex: 1,
      explanation: "LoRAは、モデル全体ではなく小さな追加パラメータのみを学習する効率的なファインチューニング手法です。学習コストとストレージを大幅に削減でき、複数の用途向けモデルを低コストで運用できます。コスト効率重視のお客様に提案できます。"
    },
    {
      id: "llm-090",
      question: "ファインチューニング用のデータ準備で重要なことは何ですか？",
      options: [
        "データ量は少ないほど良い",
        "高品質で一貫性のある入出力ペアを十分な量用意する",
        "個人情報を多く含める",
        "他社のデータを使用する"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングでは、高品質で一貫性のある入出力ペア（質問と理想的な回答のセット）が重要です。品質の低いデータで学習すると、モデルの性能も低下します。お客様には「良いデータの準備がファインチューニング成功の鍵」と伝えましょう。"
    },
    {
      id: "llm-091",
      question: "「ハイブリッド検索」とは何ですか？",
      options: [
        "複数のAIを組み合わせること",
        "ベクトル検索とキーワード検索を組み合わせて精度を向上させる手法",
        "オンラインとオフラインを組み合わせること",
        "画像とテキストを組み合わせること"
      ],
      correctIndex: 1,
      explanation: "ハイブリッド検索は、意味の類似性を捉えるベクトル検索と、特定のキーワードを正確に検索するキーワード検索を組み合わせる手法です。RAGシステムで検索精度を向上させるために用いられます。"
    },
    {
      id: "llm-092",
      question: "RAGシステムの「リランキング」とは何ですか？",
      options: [
        "検索結果の順位を上げること",
        "最初の検索結果を別のモデルで再評価し、より関連性の高い順に並べ替えること",
        "ユーザーの順位を決めること",
        "AIモデルをランク付けすること"
      ],
      correctIndex: 1,
      explanation: "リランキングは、最初の検索で得られた結果を、より精度の高いモデルで再評価し、質問への関連性が高い順に並べ替えるプロセスです。検索精度を向上させ、RAGシステムの回答品質を高められます。"
    },

    // === マルチモーダル（93-96） ===
    {
      id: "llm-093",
      question: "「マルチモーダルAI」とは何ですか？",
      options: [
        "複数のAIを同時に使うこと",
        "テキスト、画像、音声など複数の種類のデータを処理できるAI",
        "複数の言語に対応したAI",
        "複数のユーザーが使えるAI"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAIは、テキストだけでなく、画像、音声、動画など複数の種類（モダリティ）のデータを理解・生成できるAIです。GPT-4V、Gemini、Claude 3などが画像理解に対応しています。「画像を見せて質問できる」機能として、様々な業務活用が可能です。"
    },
    {
      id: "llm-094",
      question: "GPT-4Vの「V」は何を意味しますか？",
      options: [
        "Version",
        "Vision（視覚・画像理解）",
        "Virtual",
        "Velocity"
      ],
      correctIndex: 1,
      explanation: "GPT-4Vの「V」はVision（視覚）を意味し、画像を入力として受け取り、内容を理解・説明できる機能を指します。写真の説明、図表の分析、文書のスキャンデータからの情報抽出など、画像を含む業務に活用できます。"
    },
    {
      id: "llm-095",
      question: "マルチモーダルAIのビジネス活用例として適切なものはどれですか？",
      options: [
        "テキストのみの翻訳",
        "製品画像からの説明文自動生成、手書きメモのデジタル化",
        "単純な計算処理",
        "データベースの管理"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAIは、製品写真からの説明文生成、手書きメモや名刺のデジタル化、図面や設計図の解析、医療画像の説明など、画像とテキストを組み合わせた業務に活用できます。お客様の業務で画像を扱う場面を探し、活用提案しましょう。"
    },
    {
      id: "llm-096",
      question: "マルチモーダルAIの利用時の注意点は何ですか？",
      options: [
        "画像は何でも送って良い",
        "機密情報を含む画像の取り扱いや、画像内の人物のプライバシーに注意が必要",
        "画像は自動的に暗号化される",
        "画像処理は無料"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAI利用時は、機密文書の画像、個人情報を含む写真、著作権のある画像の取り扱いに注意が必要です。また、画像処理は通常のテキスト処理より料金が高い場合が多いです。お客様には適切な利用ガイドラインの策定を推奨しましょう。"
    },

    // === 温度パラメータ、トップP（97-100） ===
    {
      id: "llm-097",
      question: "LLMの「Temperature（温度）」パラメータの役割は何ですか？",
      options: [
        "AIの処理速度を制御する",
        "出力のランダム性・創造性を制御する（高いほど多様な出力）",
        "AIの消費電力を制御する",
        "AIの学習速度を制御する"
      ],
      correctIndex: 1,
      explanation: "Temperature（温度）は、出力のランダム性を制御するパラメータです。0に近いほど一貫した確定的な出力、1に近いほど多様で創造的な出力になります。事実確認には低め（0.2〜0.3）、創作には高め（0.7〜0.9）を推奨しましょう。"
    },
    {
      id: "llm-098",
      question: "「Top-P（トップP）」パラメータとは何ですか？",
      options: [
        "最高性能を意味する指標",
        "累積確率がPに達するまでの単語候補から選択する（nucleus sampling）",
        "上位P人のユーザーのみ使える機能",
        "AIの精度を表す数値"
      ],
      correctIndex: 1,
      explanation: "Top-P（nucleus sampling）は、確率の高い順に単語を並べ、累積確率がPに達するまでの候補から次の単語を選択する方式です。0.1なら上位10%の確率の単語から選択。Temperatureと組み合わせて出力の多様性を制御します。"
    },
    {
      id: "llm-099",
      question: "ビジネス文書作成に適したTemperature設定はどれですか？",
      options: [
        "1.0以上の高い値",
        "0.3〜0.5程度の低めの値",
        "設定は不要",
        "毎回ランダムに変える"
      ],
      correctIndex: 1,
      explanation: "ビジネス文書やFAQ回答など、一貫性と正確性が求められる用途では、Temperature 0.3〜0.5程度の低めの設定が適しています。一方、マーケティングコピーやアイデア出しでは0.7〜0.9の高めの設定で創造性を引き出せます。"
    },
    {
      id: "llm-100",
      question: "企業でLLMを導入する際の成功のポイントとして最も重要なものはどれですか？",
      options: [
        "最も高価なモデルを選ぶ",
        "明確なユースケースの特定と、段階的な導入・検証のアプローチ",
        "全業務を一度にAI化する",
        "AIに全ての判断を任せる"
      ],
      correctIndex: 1,
      explanation: "LLM導入の成功には、まず明確なユースケース（例：カスタマーサポート、文書要約）を特定し、小規模なPoC（概念実証）から始めて効果を検証し、徐々に拡大するアプローチが重要です。営業では「一緒に最適な導入計画を策定しましょう」と提案し、伴走型の支援を提供しましょう。"
    }
  ]
};
