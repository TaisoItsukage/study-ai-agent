import { Genre } from "../types";

export const securityEthics: Genre = {
  id: "security-ethics",
  name: "セキュリティ・倫理",
  description:
    "AI活用に伴うセキュリティリスクと倫理的配慮を学びます。顧客の不安に適切に対応できるようになりましょう。",
  icon: "🔒",
  questions: [
    {
      id: "security-ethics-1",
      question: "AI活用における「個人情報保護」で最も重要な原則はどれですか？",
      options: [
        "必要最小限のデータのみを収集し適切に管理すること",
        "できるだけ多くのデータを収集して精度を高めること",
        "個人情報は暗号化すれば自由に利用できること",
        "同意を得れば個人情報の利用目的は制限されないこと"
      ],
      correctIndex: 0,
      explanation: "個人情報保護では、目的に必要最小限のデータのみを収集し、適切な管理と利用目的の範囲内での活用が基本原則です。\n\n営業トーク例：「弊社のAIは必要最小限のデータのみを使用し、個人情報保護を徹底しています。」"
    },
    {
      id: "security-ethics-2",
      question: "AIシステムへの「プロンプトインジェクション」攻撃とは何ですか？",
      options: [
        "悪意ある入力でAIの動作を意図しない方向に誘導する攻撃",
        "AIのソースコードに悪意あるプログラムを挿入する攻撃",
        "AIサーバーに大量のリクエストを送信する攻撃",
        "AIの学習データを外部から改ざんする攻撃"
      ],
      correctIndex: 0,
      explanation: "プロンプトインジェクションは、巧妙な入力文によってAIの指示を上書きし、本来許可されていない動作をさせる攻撃手法です。\n\n営業トーク例：「弊社のAIには、プロンプトインジェクション対策の入力フィルタリングを実装しています。」"
    },
    {
      id: "security-ethics-3",
      question: "AI活用における「データの匿名化」の目的は何ですか？",
      options: [
        "個人を特定できないようにしてプライバシーを保護すること",
        "データのファイルサイズを小さくすること",
        "データの処理速度を向上させること",
        "データの正確性を高めること"
      ],
      correctIndex: 0,
      explanation: "匿名化は、氏名や住所などの個人識別情報を削除・加工し、元の個人を特定できないようにすることでプライバシーを保護する技術です。\n\n営業トーク例：「分析に使用するデータは匿名化処理を行い、個人情報保護を徹底しています。」"
    },
    {
      id: "security-ethics-4",
      question: "AIの「バイアス（偏り）」が問題となる理由は何ですか？",
      options: [
        "特定のグループに不公平な判断や差別が生じる可能性があるから",
        "AIの処理速度が低下するから",
        "AIのメンテナンスコストが増加するから",
        "AIのファイルサイズが大きくなるから"
      ],
      correctIndex: 0,
      explanation: "AIのバイアスは、学習データの偏りなどが原因で、性別、人種、年齢などに基づく不公平な判断や差別を生む可能性があります。\n\n営業トーク例：「弊社ではバイアス検出の仕組みを導入し、公平性を担保したAI運用を支援します。」"
    },
    {
      id: "security-ethics-5",
      question: "AIサービスにおける「データ暗号化」の重要性は何ですか？",
      options: [
        "通信中や保存中のデータを第三者から保護すること",
        "データの容量を圧縮して保存効率を上げること",
        "データの処理速度を向上させること",
        "データの重複を検出して削除すること"
      ],
      correctIndex: 0,
      explanation: "暗号化は、データを第三者が読めない形式に変換し、通信中（TLSなど）や保存中（AESなど）のデータを不正アクセスから保護します。\n\n営業トーク例：「全てのデータは暗号化されて保存・通信されるため、外部からの盗聴リスクを防げます。」"
    },
    {
      id: "security-ethics-6",
      question: "AIにおける「説明責任（アカウンタビリティ）」とは何ですか？",
      options: [
        "AIの判断や処理について根拠を説明できる状態を維持すること",
        "AIのソースコードを全て公開すること",
        "AIの利用料金を明細で説明すること",
        "AIの開発者の経歴を公開すること"
      ],
      correctIndex: 0,
      explanation: "説明責任は、AIがなぜその判断をしたのか、どのようなデータに基づいているのかを説明できる状態を維持し、責任の所在を明確にすることです。\n\n営業トーク例：「AIの判断根拠を記録・説明できる仕組みにより、監査対応も安心です。」"
    },
    {
      id: "security-ethics-7",
      question: "AI活用における「同意取得」で注意すべき点は何ですか？",
      options: [
        "利用目的を明確に説明し、ユーザーの明示的な同意を得ること",
        "一度同意を得れば永続的に有効であること",
        "同意書に法的な専門用語を多用すること",
        "同意取得は口頭で行えば書面は不要であること"
      ],
      correctIndex: 0,
      explanation: "AI活用のデータ利用では、何のためにどのようにデータを使うかを分かりやすく説明し、ユーザーから明示的な同意を得ることが重要です。\n\n営業トーク例：「利用者への説明と同意取得の仕組みも含めて、コンプライアンス対応をご支援します。」"
    },
    {
      id: "security-ethics-8",
      question: "AIの「学習データの著作権」について正しい認識はどれですか？",
      options: [
        "著作物を学習に使用する場合は権利者の許諾や法的根拠が必要",
        "AIの学習に使用するデータには著作権は適用されない",
        "インターネット上の公開データは自由に学習に使える",
        "著作権は個人の創作物のみに適用される"
      ],
      correctIndex: 0,
      explanation: "AI学習に著作物を使用する場合、著作権法の例外規定（日本では30条の4など）の範囲内か、権利者の許諾が必要です。\n\n営業トーク例：「弊社のAIは、著作権に配慮した適法なデータのみで学習しております。」"
    },
    {
      id: "security-ethics-9",
      question: "AIシステムの「アクセス制御」の基本原則はどれですか？",
      options: [
        "必要最小限の権限のみを付与する最小権限の原則",
        "全ての従業員に同じ権限を付与する平等の原則",
        "管理者は全てのデータにアクセスできる原則",
        "外部委託先には制限なくアクセス権を付与する原則"
      ],
      correctIndex: 0,
      explanation: "アクセス制御では、各ユーザーに業務上必要最小限の権限のみを付与する「最小権限の原則」が基本です。\n\n営業トーク例：「役割に応じた細かいアクセス制御で、情報漏洩リスクを最小化できます。」"
    },
    {
      id: "security-ethics-10",
      question: "AIの「監査ログ（Audit Log）」を記録する目的は何ですか？",
      options: [
        "誰がいつ何を行ったか追跡可能にして不正を抑止すること",
        "AIの学習精度を向上させること",
        "システムの処理速度を監視すること",
        "ユーザーの利用頻度を集計すること"
      ],
      correctIndex: 0,
      explanation: "監査ログは、システムへのアクセスや操作の記録を残し、不正行為の検知・追跡や、コンプライアンス監査への対応を可能にします。\n\n営業トーク例：「全ての操作が監査ログに記録されるため、内部統制やコンプライアンス監査にも対応できます。」"
    },
    {
      id: "security-ethics-11",
      question: "AIの「透明性」が求められる理由は何ですか？",
      options: [
        "利用者がAIの仕組みや限界を理解し適切に利用できるため",
        "AIのソースコードを公開するとセキュリティが向上するため",
        "透明性を高めると処理速度が向上するため",
        "競合他社との差別化のため"
      ],
      correctIndex: 0,
      explanation: "AIの透明性は、利用者がAIの仕組み、判断基準、限界を理解し、適切な期待値を持って活用できるようにするために重要です。\n\n営業トーク例：「AIがどのように判断しているか、分かりやすい説明資料もご用意しています。」"
    },
    {
      id: "security-ethics-12",
      question: "「GDPR（EU一般データ保護規則）」がAI活用に与える影響として正しいものはどれですか？",
      options: [
        "EU市民のデータを扱う場合は厳格なデータ保護が義務付けられる",
        "EU域内でのみAIの利用が制限される",
        "AI開発企業は必ずEUに拠点を置く必要がある",
        "GDPRは個人データではなく企業データを規制する"
      ],
      correctIndex: 0,
      explanation: "GDPRは、EU市民の個人データを扱う全ての組織に適用され、データ処理の適法性、同意取得、削除権への対応などを義務付けています。\n\n営業トーク例：「弊社サービスはGDPRに準拠しており、グローバル展開される企業様にも安心してご利用いただけます。」"
    },
    {
      id: "security-ethics-13",
      question: "AIの「フェアネス（公平性）」を確保するために重要なことは何ですか？",
      options: [
        "多様なデータで学習し、偏った判断が生じないようにすること",
        "全てのユーザーに同じ結果を返すこと",
        "処理速度を全ユーザーで均等にすること",
        "料金体系を全ユーザーで統一すること"
      ],
      correctIndex: 0,
      explanation: "AIの公平性確保では、多様性のあるデータセットで学習し、特定のグループに不利な判断が生じないよう継続的にモニタリングすることが重要です。\n\n営業トーク例：「定期的にバイアス検査を実施し、公平なAI運用を維持するサポートを提供します。」"
    },
    {
      id: "security-ethics-14",
      question: "AI活用における「データ漏洩」のリスクを軽減する方法として適切なものはどれですか？",
      options: [
        "暗号化、アクセス制御、定期的なセキュリティ監査を実施する",
        "データを大量に複製して分散保存する",
        "パスワードを全社員で共有して管理を簡素化する",
        "データバックアップを外部の無料サービスに保存する"
      ],
      correctIndex: 0,
      explanation: "データ漏洩リスクの軽減には、暗号化、適切なアクセス制御、定期的なセキュリティ監査、従業員教育など多層的な対策が必要です。\n\n営業トーク例：「多層的なセキュリティ対策により、お客様のデータを厳重に保護しています。」"
    },
    {
      id: "security-ethics-15",
      question: "AIの「利用規約」に含めるべき重要な事項はどれですか？",
      options: [
        "AIの利用目的、制限事項、免責事項、データの取扱い方針",
        "AIの技術的な実装詳細とソースコード",
        "競合他社との機能比較結果",
        "開発チームの経歴とスキルセット"
      ],
      correctIndex: 0,
      explanation: "利用規約には、AIの利用目的と範囲、禁止事項、免責事項、個人情報の取扱い、変更通知などを明記することが重要です。\n\n営業トーク例：「明確な利用規約を整備しており、御社の法務部門にもご確認いただけます。」"
    },
    {
      id: "security-ethics-16",
      question: "AI活用における「人間による最終判断」の重要性は何ですか？",
      options: [
        "AIの判断を人間が検証し、誤りや不適切な結果を防ぐため",
        "AIのコストを削減するため",
        "AIの処理速度を向上させるため",
        "AIの利用者数を制限するため"
      ],
      correctIndex: 0,
      explanation: "AIは完璧ではないため、特に重要な判断（採用、融資、医療など）では人間が最終確認を行い、誤りや不公平を防ぐことが重要です。\n\n営業トーク例：「最終判断は必ず人間が行う運用フローをご提案し、AIの誤りによるリスクを防ぎます。」"
    },
    {
      id: "security-ethics-17",
      question: "AIシステムの「脆弱性診断」を定期的に行う理由は何ですか？",
      options: [
        "新たなセキュリティリスクを早期に発見し対策するため",
        "AIの学習精度を向上させるため",
        "システムの処理速度を改善するため",
        "利用者数の増加に対応するため"
      ],
      correctIndex: 0,
      explanation: "脆弱性診断は、システムに存在するセキュリティ上の弱点を定期的にチェックし、攻撃者に悪用される前に対策を講じるために行います。\n\n営業トーク例：「定期的な脆弱性診断を実施し、常に最新のセキュリティ対策を維持しています。」"
    },
    {
      id: "security-ethics-18",
      question: "AIの「誤判断」が発生した場合の適切な対応はどれですか？",
      options: [
        "原因を分析し、再発防止策を講じてモデルを改善する",
        "誤判断は想定内として特に対応しない",
        "問題が起きたデータを削除して隠蔽する",
        "AIの利用を即座に全面停止する"
      ],
      correctIndex: 0,
      explanation: "AIの誤判断発生時は、原因を分析し、再発防止策（データの追加、モデルの再学習、ルールの追加など）を講じて継続的に改善することが重要です。\n\n営業トーク例：「誤判断が発生した場合の分析・改善プロセスも含めた運用支援をご提供します。」"
    },
    {
      id: "security-ethics-19",
      question: "AI活用における「データ保持期間」の設定で考慮すべきことは何ですか？",
      options: [
        "法令で定められた期間と業務上の必要性のバランス",
        "データは永久に保持するのが最も安全である",
        "ストレージコストだけを基準に決定する",
        "競合他社の保持期間に合わせる"
      ],
      correctIndex: 0,
      explanation: "データ保持期間は、法令で定められた保存義務期間と、業務上の必要性を考慮し、不要になったデータは適切に削除する方針が必要です。\n\n営業トーク例：「法令遵守と業務効率の両面から、最適なデータ保持ポリシーをご提案します。」"
    },
    {
      id: "security-ethics-20",
      question: "AIの「倫理ガイドライン」を策定する目的は何ですか？",
      options: [
        "AI活用における判断基準を明確にし、適切な利用を促進すること",
        "AIの技術仕様を文書化すること",
        "AIの利用料金を設定すること",
        "AIの開発スケジュールを管理すること"
      ],
      correctIndex: 0,
      explanation: "倫理ガイドラインは、AIを開発・利用する際の判断基準や行動指針を明確にし、社会的に受け入れられる適切な活用を促進するために策定します。\n\n営業トーク例：「御社のAI倫理ガイドライン策定もご支援し、責任あるAI活用を実現します。」"
    },
    {
      id: "security-ethics-21",
      question: "AIシステムにおける「二要素認証」の目的は何ですか？",
      options: [
        "パスワードだけでなく追加の認証手段でセキュリティを強化すること",
        "二人の承認がないとシステムを使えないようにすること",
        "二つの異なるAIモデルで判断を検証すること",
        "二段階でデータを暗号化すること"
      ],
      correctIndex: 0,
      explanation: "二要素認証は、パスワード（知識）に加えて、スマートフォン（所持）や指紋（生体）など、異なる要素を組み合わせて本人確認の精度を高めます。\n\n営業トーク例：「二要素認証に対応しており、不正アクセスのリスクを大幅に軽減できます。」"
    },
    {
      id: "security-ethics-22",
      question: "AIが生成したコンテンツの「著作権」に関する一般的な考え方はどれですか？",
      options: [
        "AIのみで生成された作品の著作権は法的に不明確な部分がある",
        "AIが生成した全てのコンテンツに著作権は発生しない",
        "AIが生成したコンテンツの著作権は全てAI開発企業に帰属する",
        "AIが生成したコンテンツは全て自由に商用利用できる"
      ],
      correctIndex: 0,
      explanation: "AIが生成したコンテンツの著作権は、各国の法律で解釈が異なり、人間の創作的関与の程度によって判断が分かれる法的に不明確な領域です。\n\n営業トーク例：「AI生成コンテンツの著作権については、利用規約で権利関係を明確にしています。」"
    },
    {
      id: "security-ethics-23",
      question: "AI活用における「リスクアセスメント」の目的は何ですか？",
      options: [
        "AI導入に伴うリスクを特定・評価し、対策を計画すること",
        "AIの投資対効果を算出すること",
        "AIモデルの精度を評価すること",
        "AIプロジェクトのスケジュールを策定すること"
      ],
      correctIndex: 0,
      explanation: "リスクアセスメントは、AI導入に伴う潜在的なリスク（セキュリティ、プライバシー、倫理など）を特定・評価し、適切な対策を計画するプロセスです。\n\n営業トーク例：「導入前のリスクアセスメントから対策の実装まで、一貫してサポートいたします。」"
    },
    {
      id: "security-ethics-24",
      question: "AIの「ブラックボックス問題」とは何ですか？",
      options: [
        "AIの判断過程が複雑で人間に理解しにくい問題",
        "AIのハードウェアが黒い筐体に入っている問題",
        "AIのソースコードが非公開である問題",
        "AIの画面が暗くて見えにくい問題"
      ],
      correctIndex: 0,
      explanation: "ブラックボックス問題は、特にディープラーニングにおいて、AIがなぜその判断をしたのか、内部の推論過程が人間に理解しにくいことを指します。\n\n営業トーク例：「判断根拠を可視化する説明可能AI機能により、ブラックボックス問題に対応しています。」"
    },
    {
      id: "security-ethics-25",
      question: "AI活用における「コンプライアンス」の重要性は何ですか？",
      options: [
        "法令や規則を遵守し、社会的信頼を維持すること",
        "AIの処理速度を最大化すること",
        "AIの導入コストを最小化すること",
        "AIの機能を最大限に活用すること"
      ],
      correctIndex: 0,
      explanation: "コンプライアンスは、個人情報保護法、業界規制、社内規程などを遵守し、法的リスクの回避と社会的信頼の維持を図ることです。\n\n営業トーク例：「法令遵守を徹底した設計で、コンプライアンスリスクを最小化できます。」"
    },
    {
      id: "security-ethics-26",
      question: "AIシステムの「インシデント対応」で最初に行うべきことは何ですか？",
      options: [
        "被害の拡大を防ぐため、影響範囲を特定し封じ込める",
        "原因究明のために詳細な調査を開始する",
        "関係者全員に一斉にメールで報告する",
        "システムを完全に再構築する"
      ],
      correctIndex: 0,
      explanation: "インシデント発生時は、まず被害の拡大を防ぐため影響範囲を特定し、必要に応じてシステムの隔離などの封じ込め措置を行います。\n\n営業トーク例：「インシデント発生時の対応手順も整備しており、迅速な対応が可能です。」"
    },
    {
      id: "security-ethics-27",
      question: "AI活用における「同意の撤回権」とは何ですか？",
      options: [
        "ユーザーがいつでもデータ利用への同意を取り消せる権利",
        "AIサービスの契約をいつでも解約できる権利",
        "AIの判断結果に異議を申し立てる権利",
        "AIの開発方針に意見を述べる権利"
      ],
      correctIndex: 0,
      explanation: "同意の撤回権は、ユーザーが過去に与えたデータ利用への同意をいつでも取り消し、自分のデータの利用停止や削除を求められる権利です。\n\n営業トーク例：「ユーザーからの同意撤回リクエストに対応できる仕組みを実装しています。」"
    },
    {
      id: "security-ethics-28",
      question: "AIの「敵対的攻撃（Adversarial Attack）」とは何ですか？",
      options: [
        "AIを騙すために意図的に加工された入力でAIを誤動作させる攻撃",
        "複数のハッカーが協力してAIシステムを攻撃すること",
        "AIを使って他のシステムを攻撃すること",
        "AI開発企業間の競争を妨害する行為"
      ],
      correctIndex: 0,
      explanation: "敵対的攻撃は、人間には気づかない微細なノイズを画像などに加えてAIを誤認識させるなど、AIの弱点を突く攻撃手法です。\n\n営業トーク例：「敵対的攻撃への耐性を高めるセキュリティ対策を実装しています。」"
    },
    {
      id: "security-ethics-29",
      question: "AI活用における「データ主権」の概念とは何ですか？",
      options: [
        "データの所有者や生成者がデータの管理権限を持つこと",
        "データを最初に収集した企業が全ての権利を持つこと",
        "政府がすべてのデータを管理すること",
        "データは誰のものでもなく自由に使えること"
      ],
      correctIndex: 0,
      explanation: "データ主権は、個人や組織が自らのデータに対して管理・決定権を持ち、データの利用方法をコントロールできるという概念です。\n\n営業トーク例：「お客様のデータ主権を尊重し、データの管理権限は御社にあることを明確にしています。」"
    },
    {
      id: "security-ethics-30",
      question: "AIシステムの「セキュリティバイデザイン」とは何ですか？",
      options: [
        "設計段階からセキュリティを組み込んでシステムを構築すること",
        "セキュリティ専門家がシステム設計を担当すること",
        "セキュリティ機能のUIデザインを重視すること",
        "セキュリティテストを設計書に記載すること"
      ],
      correctIndex: 0,
      explanation: "セキュリティバイデザインは、システム開発の設計段階からセキュリティ要件を組み込み、後付けではなく本質的に安全なシステムを構築する考え方です。\n\n営業トーク例：「設計段階からセキュリティを考慮したセキュリティバイデザインで開発しています。」"
    },
    {
      id: "security-ethics-31",
      question: "AIの「ハルシネーション」が引き起こすセキュリティリスクは何ですか？",
      options: [
        "AIが誤った情報を事実として提供し、誤判断を招く可能性",
        "AIが幻覚を見て機能停止する可能性",
        "AIがハッカーに乗っ取られる可能性",
        "AIが自己増殖して制御不能になる可能性"
      ],
      correctIndex: 0,
      explanation: "ハルシネーションにより、AIがもっともらしい誤情報を生成し、それを信じた利用者が誤った判断や行動をとるリスクがあります。\n\n営業トーク例：「AIの出力を人間が確認するワークフローを組み込み、ハルシネーションリスクに対応します。」"
    },
    {
      id: "security-ethics-32",
      question: "AI活用における「プライバシー・バイ・デザイン」の原則とは何ですか？",
      options: [
        "システム設計の初期段階からプライバシー保護を組み込むこと",
        "プライバシー設定画面のデザインを重視すること",
        "プライバシーポリシーを詳細に記載すること",
        "プライバシー専門家を開発チームに配置すること"
      ],
      correctIndex: 0,
      explanation: "プライバシー・バイ・デザインは、システムの企画・設計段階からプライバシー保護を考慮し、後から追加するのではなく本質的に保護された設計にする原則です。\n\n営業トーク例：「プライバシー・バイ・デザインの原則に基づき、設計段階からプライバシー保護を組み込んでいます。」"
    },
    {
      id: "security-ethics-33",
      question: "AIシステムにおける「ゼロトラスト」セキュリティモデルとは何ですか？",
      options: [
        "全てのアクセスを検証し、何も信頼しないことを前提とするモデル",
        "セキュリティリスクがゼロになることを目指すモデル",
        "信頼できるユーザーには全てのアクセスを許可するモデル",
        "セキュリティ対策のコストをゼロにするモデル"
      ],
      correctIndex: 0,
      explanation: "ゼロトラストは、「内部も外部も信頼しない」を前提に、全てのアクセスを検証・認可し、継続的に監視するセキュリティモデルです。\n\n営業トーク例：「ゼロトラストモデルを採用し、社内からのアクセスも含めて厳格に認証しています。」"
    },
    {
      id: "security-ethics-34",
      question: "AIの「モデル盗用（Model Stealing）」攻撃とは何ですか？",
      options: [
        "AIに多数のクエリを送信してモデルを複製・推測する攻撃",
        "AIのソースコードを不正にコピーする攻撃",
        "AIのサーバーを物理的に盗む攻撃",
        "AIの学習データを外部に流出させる攻撃"
      ],
      correctIndex: 0,
      explanation: "モデル盗用は、AIサービスに多数のクエリを送信し、その入出力パターンから元のモデルを推測・複製する攻撃手法です。\n\n営業トーク例：「異常なクエリパターンを検知し、モデル盗用攻撃を防ぐ仕組みを実装しています。」"
    },
    {
      id: "security-ethics-35",
      question: "AI活用における「データポータビリティ」の権利とは何ですか？",
      options: [
        "ユーザーが自分のデータを別のサービスに移行できる権利",
        "データをモバイル端末で閲覧できる権利",
        "データをクラウドに保存できる権利",
        "データを複数の場所にバックアップできる権利"
      ],
      correctIndex: 0,
      explanation: "データポータビリティは、ユーザーが自分のデータを機械可読形式で受け取り、別のサービス提供者に移行できる権利です（GDPRで規定）。\n\n営業トーク例：「データポータビリティに対応しており、お客様のデータを標準形式でエクスポートできます。」"
    },
    {
      id: "security-ethics-36",
      question: "AIシステムの「セキュリティ認証」（ISO27001等）を取得する意義は何ですか？",
      options: [
        "第三者機関によってセキュリティ管理が適切であると証明されること",
        "セキュリティ対策のコストを削減できること",
        "セキュリティインシデントが発生しなくなること",
        "全てのセキュリティリスクが解消されること"
      ],
      correctIndex: 0,
      explanation: "ISO27001などのセキュリティ認証は、第三者機関による審査を通じて、情報セキュリティ管理体制が国際基準を満たしていることを証明します。\n\n営業トーク例：「ISO27001認証を取得しており、第三者機関によるセキュリティ管理の適切性が証明されています。」"
    },
    {
      id: "security-ethics-37",
      question: "AI活用における「忘れられる権利」とは何ですか？",
      options: [
        "個人がデータの削除を要求し、検索結果などから消去される権利",
        "AIがユーザーの過去の入力を忘れる機能",
        "サービス解約後にアカウントが自動削除される権利",
        "古いデータが自動的に削除される仕組み"
      ],
      correctIndex: 0,
      explanation: "忘れられる権利（削除権）は、個人が自分に関するデータの削除を要求し、検索結果やデータベースから消去される権利です（GDPRで規定）。\n\n営業トーク例：「『忘れられる権利』に対応しており、削除要求に速やかに対応できる仕組みを整えています。」"
    },
    {
      id: "security-ethics-38",
      question: "AIの「データポイズニング」攻撃とは何ですか？",
      options: [
        "学習データに悪意あるデータを混入させてAIを誤学習させる攻撃",
        "AIのデータベースを暗号化して身代金を要求する攻撃",
        "AIの出力結果を改ざんする攻撃",
        "AIへの入力データを大量に送信してサーバーを停止させる攻撃"
      ],
      correctIndex: 0,
      explanation: "データポイズニングは、AIの学習データに意図的に不正なデータを混入させ、モデルの判断を歪めたり、バックドアを仕込んだりする攻撃手法です。\n\n営業トーク例：「学習データの品質検証プロセスにより、データポイズニング攻撃のリスクを軽減しています。」"
    },
    {
      id: "security-ethics-39",
      question: "AI活用における「倫理的AI」の重要な要素として正しいものはどれですか？",
      options: [
        "公平性、透明性、プライバシー保護、説明責任の確保",
        "高速な処理速度と低コストでの運用",
        "最先端の技術とハードウェアの採用",
        "グローバルな市場での高いシェア獲得"
      ],
      correctIndex: 0,
      explanation: "倫理的AIには、公平性（バイアスのない判断）、透明性（判断過程の説明）、プライバシー保護、説明責任などの要素が重要です。\n\n営業トーク例：「倫理的AIの原則に基づき、公平性と透明性を重視した運用をご支援します。」"
    },
    {
      id: "security-ethics-40",
      question: "AIシステムの「事業継続計画（BCP）」に含めるべき内容はどれですか？",
      options: [
        "災害や障害発生時のサービス復旧手順と代替手段",
        "AIモデルの学習アルゴリズムの詳細仕様",
        "競合他社との機能比較分析",
        "新機能の開発ロードマップ"
      ],
      correctIndex: 0,
      explanation: "BCPには、災害、サイバー攻撃、システム障害などの緊急事態発生時に、サービスを継続または迅速に復旧するための手順と代替手段を含めます。\n\n営業トーク例：「BCPを整備しており、万が一の障害時も迅速な復旧が可能です。」"
    },
    {
      id: "security-ethics-41",
      question: "AI活用における「差別禁止」の観点で注意すべきことは何ですか？",
      options: [
        "AIの判断が性別や人種などで不当な差別を生まないよう監視すること",
        "AIの利用料金を全ての顧客で同一にすること",
        "AIの機能を全てのユーザーで同じにすること",
        "AIの処理速度をユーザー間で均等にすること"
      ],
      correctIndex: 0,
      explanation: "AIの差別禁止では、採用、融資、保険などの判断において、性別、人種、年齢、障害などに基づく不当な差別が生じないよう監視することが重要です。\n\n営業トーク例：「定期的な公平性監査により、差別的な判断が生じていないかモニタリングしています。」"
    },
    {
      id: "security-ethics-42",
      question: "AIの「ログ管理」で保存すべき情報として適切なものはどれですか？",
      options: [
        "入力データ、出力結果、アクセス者、タイムスタンプ",
        "ユーザーの個人的な会話内容の全て",
        "競合他社の利用状況",
        "開発チームの作業履歴のみ"
      ],
      correctIndex: 0,
      explanation: "AIのログ管理では、誰が、いつ、どのような入力を行い、どのような結果が出力されたかを記録し、監査やトラブル対応に備えます。\n\n営業トーク例：「適切なログ管理により、問題発生時の原因追跡やコンプライアンス監査に対応できます。」"
    },
    {
      id: "security-ethics-43",
      question: "AIサービスにおける「SLA（サービスレベル契約）」に含めるべき項目はどれですか？",
      options: [
        "稼働率保証、応答時間、セキュリティ基準、サポート対応時間",
        "AIモデルの学習アルゴリズムの詳細",
        "開発チームの人員構成",
        "競合他社との価格比較"
      ],
      correctIndex: 0,
      explanation: "SLAには、サービスの稼働率保証、応答時間、セキュリティ基準、障害時のサポート対応時間など、品質に関する合意事項を明記します。\n\n営業トーク例：「稼働率99.9%を保証するSLAをご用意しており、安定したサービス提供をお約束します。」"
    },
    {
      id: "security-ethics-44",
      question: "AI活用における「インフォームドコンセント」の原則とは何ですか？",
      options: [
        "十分な情報提供を受けた上で利用者が同意を行うこと",
        "AIに関する情報を全て公開すること",
        "同意書に署名捺印を必ず求めること",
        "AIの判断に同意してから結果を受け取ること"
      ],
      correctIndex: 0,
      explanation: "インフォームドコンセントは、AIの利用目的、データの取扱い、リスクなどについて十分な説明を受けた上で、利用者が理解して同意することです。\n\n営業トーク例：「利用者に分かりやすく説明し、理解いただいた上で同意を得る仕組みを整えています。」"
    },
    {
      id: "security-ethics-45",
      question: "AIの「レギュラトリーサンドボックス」とは何ですか？",
      options: [
        "規制を一時的に緩和してAIの実証実験を行える制度",
        "AIを安全な隔離環境で実行する技術",
        "規制当局がAI企業を監督する仕組み",
        "AIの開発を規制する法律の総称"
      ],
      correctIndex: 0,
      explanation: "レギュラトリーサンドボックスは、既存の規制を一時的に緩和し、革新的なAIサービスの実証実験を限定的な環境で行える制度です。\n\n営業トーク例：「新しい取り組みについては、サンドボックス制度の活用も視野に入れてご提案できます。」"
    },
    {
      id: "security-ethics-46",
      question: "AIシステムの「脅威モデリング」の目的は何ですか？",
      options: [
        "潜在的な脅威を体系的に分析し、対策の優先順位を決めること",
        "AIモデルの精度を向上させること",
        "AIシステムの処理速度を最適化すること",
        "AIの利用者数を予測すること"
      ],
      correctIndex: 0,
      explanation: "脅威モデリングは、システムに対する潜在的な脅威（攻撃者、攻撃手法、脆弱性など）を体系的に分析し、効果的な対策を計画する手法です。\n\n営業トーク例：「脅威モデリングに基づいた対策を実施し、優先度の高いリスクから確実に対応しています。」"
    },
    {
      id: "security-ethics-47",
      question: "AI活用における「人間中心のAI」の考え方とは何ですか？",
      options: [
        "AIは人間を支援するツールであり、最終判断は人間が行うこと",
        "AIの開発には必ず人間が関わること",
        "AIを人間の形に近づけること",
        "AIの利用は人間に限定すること"
      ],
      correctIndex: 0,
      explanation: "人間中心のAIは、AIは人間の能力を拡張・支援するツールであり、重要な意思決定の最終責任は人間にあるという考え方です。\n\n営業トーク例：「人間中心の考え方に基づき、AIは判断を支援し、最終決定は人が行う設計にしています。」"
    },
    {
      id: "security-ethics-48",
      question: "AIの「セキュリティパッチ管理」で重要なことは何ですか？",
      options: [
        "脆弱性が発見されたら速やかにパッチを適用すること",
        "パッチは年に一度まとめて適用すること",
        "パッチ適用は利用者の判断に任せること",
        "パッチよりも新機能の追加を優先すること"
      ],
      correctIndex: 0,
      explanation: "セキュリティパッチ管理では、脆弱性が発見されたら速やかにパッチを検証・適用し、攻撃者に悪用される前に対策することが重要です。\n\n営業トーク例：「セキュリティパッチは速やかに適用し、常に最新の保護状態を維持しています。」"
    },
    {
      id: "security-ethics-49",
      question: "AI活用における「ステークホルダーへの説明責任」が求められる理由は何ですか？",
      options: [
        "AI導入の影響を受ける関係者の理解と信頼を得るため",
        "AIの技術仕様を全員に理解させるため",
        "AIの導入コストを関係者で分担するため",
        "AIの開発スケジュールを共有するため"
      ],
      correctIndex: 0,
      explanation: "ステークホルダー（従業員、顧客、株主、規制当局など）への説明責任を果たすことで、AI活用への理解と信頼を得ることができます。\n\n営業トーク例：「経営層や従業員の皆様への説明資料作成もご支援し、組織全体の理解を促進します。」"
    },
    {
      id: "security-ethics-50",
      question: "AI倫理において「信頼できるAI」の条件として重要なものはどれですか？",
      options: [
        "技術的堅牢性、プライバシー保護、透明性、公平性の確保",
        "高速な処理速度と低い運用コスト",
        "最新の技術とハードウェアの採用",
        "多くの企業での導入実績"
      ],
      correctIndex: 0,
      explanation: "信頼できるAIには、技術的な堅牢性とセキュリティ、プライバシーとデータガバナンス、透明性、多様性と公平性などの要素が求められます。\n\n営業トーク例：「『信頼できるAI』の要件を満たすよう設計されており、安心してご活用いただけます。」"
    }
  ],
};
