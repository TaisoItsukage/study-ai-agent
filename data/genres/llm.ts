import { Genre } from "../types";

export const llm: Genre = {
  id: "llm",
  name: "大規模言語モデル (LLM)",
  description:
    "ChatGPTやClaudeなどの大規模言語モデルの仕組みと特徴を学びます。最も注目されているAI技術の基礎を理解しましょう。",
  icon: "💬",
  questions: [
    {
      id: "llm-1",
      question: "LLMの正式名称として正しいものはどれですか？",
      options: [
        "Large Language Model",
        "Long Learning Machine",
        "Logical Language Module",
        "Linear Learning Method",
      ],
      correctIndex: 0,
      explanation:
        "LLMはLarge Language Model（大規模言語モデル）の略です。営業トーク例：「LLMとは大規模言語モデルのことで、ChatGPTやClaudeがその代表例です」",
    },
    {
      id: "llm-2",
      question: "LLMが学習に使用するデータとして最も適切なものはどれですか？",
      options: [
        "インターネット上の大量のテキスト",
        "人間の脳波から取得したデータ情報",
        "工場のセンサーから得た数値データ",
        "衛星から受信した位置情報データ",
      ],
      correctIndex: 0,
      explanation:
        "LLMはウェブページ、書籍、論文など大量のテキストデータで学習されています。営業トーク例：「膨大なテキストデータで学習しているため、様々な業界の知識を持っています」",
    },
    {
      id: "llm-3",
      question: "Transformerアーキテクチャの特徴として正しいものはどれですか？",
      options: [
        "自己注意機構により文脈を理解する",
        "順番に一文字ずつ処理する仕組み",
        "画像データ専用に設計された構造",
        "音声データのみを扱う設計思想",
      ],
      correctIndex: 0,
      explanation:
        "Transformerは自己注意（Self-Attention）機構で文全体の文脈を捉えます。営業トーク例：「Transformer技術により、長い文章でも文脈を正確に理解できます」",
    },
    {
      id: "llm-4",
      question: "LLMにおける「トークン」とは何ですか？",
      options: [
        "テキストを分割した最小処理単位",
        "ユーザー認証に使用する鍵情報",
        "モデルの学習に必要な費用金額",
        "AIシステムへのアクセス権限情報",
      ],
      correctIndex: 0,
      explanation:
        "トークンはテキストを分割した最小単位で、単語や文字の一部を表します。営業トーク例：「トークン数に基づいて料金が発生するため、効率的なプロンプト設計でコスト最適化が可能です」",
    },
    {
      id: "llm-5",
      question: "LLMの「コンテキストウィンドウ」とは何ですか？",
      options: [
        "一度に処理できるトークンの上限数",
        "画面に表示されるUIの表示領域",
        "モデルの学習に使った期間のこと",
        "開発者が確認するデバッグ画面情報",
      ],
      correctIndex: 0,
      explanation:
        "コンテキストウィンドウはモデルが一度に扱えるトークン数の上限です。営業トーク例：「128Kトークンのコンテキストウィンドウがあるため、長文の契約書も一度に処理できます」",
    },
    {
      id: "llm-6",
      question: "ChatGPTを開発した企業はどこですか？",
      options: [
        "OpenAI社が開発した製品です",
        "Google社が開発した製品です",
        "Microsoft社が開発しました",
        "Meta社が開発した製品です",
      ],
      correctIndex: 0,
      explanation:
        "ChatGPTはOpenAI社が開発した対話型AIです。営業トーク例：「OpenAI社のChatGPTは世界で最も普及したLLMの一つで、API連携も可能です」",
    },
    {
      id: "llm-7",
      question: "Claudeを開発した企業はどこですか？",
      options: [
        "Anthropic社が開発しました",
        "OpenAI社が開発した製品です",
        "Google社が開発した製品です",
        "Amazon社が開発した製品です",
      ],
      correctIndex: 0,
      explanation:
        "ClaudeはAnthropic社が開発した対話型AIで、安全性に配慮した設計が特徴です。営業トーク例：「Anthropic社のClaudeは安全性と長文処理に優れ、ビジネス用途に最適です」",
    },
    {
      id: "llm-8",
      question: "LLMの「ハルシネーション」への対策として有効なものはどれですか？",
      options: [
        "事実確認や外部データとの照合検証",
        "より大きなモデルに変更すること",
        "処理速度を向上させる施策を実施",
        "ユーザー数を制限する運用対策",
      ],
      correctIndex: 0,
      explanation:
        "ハルシネーション対策にはRAGや外部データベースとの照合が有効です。営業トーク例：「御社のナレッジベースと連携することで、ハルシネーションを抑制し正確な回答を実現します」",
    },
    {
      id: "llm-9",
      question: "RAG（Retrieval-Augmented Generation）の役割はどれですか？",
      options: [
        "外部知識を検索して回答精度を向上",
        "モデルのパラメータ数を削減する技術",
        "学習速度を高速化するための手法",
        "ユーザーインターフェースを改善",
      ],
      correctIndex: 0,
      explanation:
        "RAGは外部データベースから関連情報を検索し、回答生成に活用する技術です。営業トーク例：「RAGにより御社の最新マニュアルを参照した正確な回答を生成できます」",
    },
    {
      id: "llm-10",
      question: "LLMの「temperature」パラメータの効果はどれですか？",
      options: [
        "出力のランダム性と創造性を調整",
        "処理にかかる時間を制御する設定",
        "使用するメモリ量を制限する項目",
        "一度に処理するデータ量を設定",
      ],
      correctIndex: 0,
      explanation:
        "temperatureは出力のランダム性を制御し、高いほど創造的になります。営業トーク例：「定型回答が必要な場合は低いtemperature、アイデア出しには高い設定が効果的です」",
    },
    {
      id: "llm-11",
      question: "LLMの「ファインチューニング」で期待できる効果はどれですか？",
      options: [
        "特定分野での回答精度向上が可能",
        "モデルの処理速度が大幅に向上",
        "必要な計算リソースが削減される",
        "ハルシネーションが完全に消滅",
      ],
      correctIndex: 0,
      explanation:
        "ファインチューニングにより特定分野や企業固有の表現に最適化できます。営業トーク例：「御社の業界用語や社内ルールを学習させ、専用AIを構築できます」",
    },
    {
      id: "llm-12",
      question: "「プロンプト」とは何を指しますか？",
      options: [
        "LLMへの入力テキストや指示内容",
        "LLMが出力する回答テキスト結果",
        "モデルの学習に使用するデータ群",
        "システムの起動に必要な設定情報",
      ],
      correctIndex: 0,
      explanation:
        "プロンプトはLLMに与える入力テキストや指示のことです。営業トーク例：「適切なプロンプト設計により、業務に特化した高品質な出力を得られます」",
    },
    {
      id: "llm-13",
      question: "LLMの「推論」と「学習」の違いとして正しいものはどれですか？",
      options: [
        "推論は予測実行で学習はパラメータ調整",
        "推論と学習は同じ処理を指している",
        "推論の方が学習より時間がかかる",
        "学習はユーザーが行い推論はAI実行",
      ],
      correctIndex: 0,
      explanation:
        "推論は学習済みモデルで予測を行い、学習はモデルのパラメータを調整します。営業トーク例：「学習は初期構築時のみ、日常運用は推論処理なのでコストを抑えられます」",
    },
    {
      id: "llm-14",
      question: "LLMのAPI利用時の課金方式として一般的なものはどれですか？",
      options: [
        "使用したトークン数に応じた従量課金",
        "月額固定料金のサブスクリプション",
        "初期導入時の一括払いのみで完結",
        "ユーザー数に応じたライセンス課金",
      ],
      correctIndex: 0,
      explanation:
        "多くのLLM APIは入出力トークン数に基づく従量課金制です。営業トーク例：「使った分だけの課金なので、スモールスタートでコストを抑えながら導入できます」",
    },
    {
      id: "llm-15",
      question: "GPT-4などの「マルチモーダル」機能で可能なことはどれですか？",
      options: [
        "画像とテキストを同時に理解して処理",
        "複数の言語を同時に翻訳処理する",
        "複数のユーザーが同時に利用可能",
        "複数のサーバーで分散処理を実行",
      ],
      correctIndex: 0,
      explanation:
        "マルチモーダルLLMは画像とテキストなど複数種類のデータを同時に処理できます。営業トーク例：「画像を見せて説明を求めたり、図面から情報を抽出したりできます」",
    },
    {
      id: "llm-16",
      question: "LLMにおける「few-shot learning」とは何ですか？",
      options: [
        "少数の例示で新しいタスクに対応する",
        "少量のデータでモデルを学習させる",
        "短時間で学習を完了させる手法",
        "少ないパラメータでモデル構築する",
      ],
      correctIndex: 0,
      explanation:
        "few-shot learningはプロンプトに数例を示すことで新タスクに対応させる手法です。営業トーク例：「数個の例を示すだけで御社固有のフォーマットに対応した出力が可能です」",
    },
    {
      id: "llm-17",
      question: "LLMの「zero-shot」能力とは何を指しますか？",
      options: [
        "例示なしで新しいタスクを実行可能",
        "エラーなしで処理を完了できる能力",
        "学習なしでモデルが動作すること",
        "コストなしでAPIを利用できること",
      ],
      correctIndex: 0,
      explanation:
        "zero-shotは事前の例示なしで新しいタスクを実行できる能力です。営業トーク例：「特別な設定なしでも、指示するだけで様々なタスクに対応できます」",
    },
    {
      id: "llm-18",
      question: "LLMの「埋め込み（Embedding）」の用途として正しいものはどれですか？",
      options: [
        "テキストをベクトル化して類似検索",
        "画像の中にテキストを埋め込む処理",
        "暗号化してセキュリティを強化する",
        "データベースにテキストを格納する",
      ],
      correctIndex: 0,
      explanation:
        "埋め込みはテキストを数値ベクトルに変換し、意味的な類似検索を可能にします。営業トーク例：「類似文書の検索やFAQ検索システムの精度向上に活用できます」",
    },
    {
      id: "llm-19",
      question: "LLMを業務で活用する際の注意点として重要なものはどれですか？",
      options: [
        "機密情報の取り扱いとセキュリティ",
        "処理速度の最大化を最優先する",
        "常に最新モデルを使用するべき",
        "コスト削減のみを重視して運用",
      ],
      correctIndex: 0,
      explanation:
        "LLM活用では機密情報の漏洩防止とセキュリティ対策が最重要です。営業トーク例：「機密データはオンプレミス環境で処理する選択肢もご提案できます」",
    },
    {
      id: "llm-20",
      question: "「GPT」の正式名称として正しいものはどれですか？",
      options: [
        "Generative Pre-trained Transformer",
        "General Purpose Technology System",
        "Global Processing Technology Unit",
        "Graphic Processing Tensor Module",
      ],
      correctIndex: 0,
      explanation:
        "GPTはGenerative Pre-trained Transformerの略です。営業トーク例：「GPTは事前学習済みの生成AIで、OpenAI社のChatGPTの基盤技術です」",
    },
    {
      id: "llm-21",
      question: "LLMの「システムプロンプト」の役割はどれですか？",
      options: [
        "AIの振る舞いや役割を事前に定義",
        "ユーザーが入力する質問テキスト",
        "AIが出力する回答の形式を指定",
        "エラー時に表示するメッセージ設定",
      ],
      correctIndex: 0,
      explanation:
        "システムプロンプトはAIの人格や制約を設定する隠れた指示です。営業トーク例：「システムプロンプトで御社の接客方針に沿った応対を設定できます」",
    },
    {
      id: "llm-22",
      question: "LLMの「ストリーミング出力」のメリットはどれですか？",
      options: [
        "回答を逐次表示しユーザー体験向上",
        "データを圧縮して転送量を削減する",
        "複数ユーザーに同時配信できること",
        "バックグラウンドで処理を継続可能",
      ],
      correctIndex: 0,
      explanation:
        "ストリーミングは生成中のテキストを逐次表示し、待ち時間を体感的に短縮します。営業トーク例：「ストリーミング対応でユーザーは待ち時間のストレスなく利用できます」",
    },
    {
      id: "llm-23",
      question: "LLMにおける「トークン制限」を超えた場合どうなりますか？",
      options: [
        "古い情報から切り捨てて処理継続",
        "自動的にモデルがアップグレード",
        "処理速度が大幅に低下する現象",
        "料金が無制限に加算される仕組み",
      ],
      correctIndex: 0,
      explanation:
        "トークン制限を超えると古い会話履歴から削除されます。営業トーク例：「長い会話では要点を要約しながら進めることで、重要な情報を維持できます」",
    },
    {
      id: "llm-24",
      question: "LLMの「モデルサイズ」が大きいとどのような傾向がありますか？",
      options: [
        "精度向上するが計算コストも増大",
        "精度は変わらずコストのみ削減",
        "処理速度が向上してコストも削減",
        "精度低下するがコストは削減される",
      ],
      correctIndex: 0,
      explanation:
        "モデルサイズが大きいほど一般に精度は向上しますが、計算コストも増加します。営業トーク例：「用途に応じて適切なモデルサイズを選定し、コストと精度のバランスを最適化します」",
    },
    {
      id: "llm-25",
      question: "LLMの「レイテンシ」とは何を指しますか？",
      options: [
        "入力から出力までの応答時間遅延",
        "モデルの学習に要する時間のこと",
        "サーバーのダウンタイムの長さ",
        "ユーザーの待機時間の許容限界",
      ],
      correctIndex: 0,
      explanation:
        "レイテンシは入力してから出力が返るまでの遅延時間です。営業トーク例：「低レイテンシを実現し、リアルタイムでの顧客対応に対応できます」",
    },
    {
      id: "llm-26",
      question: "LLMの「トークナイザ」の役割はどれですか？",
      options: [
        "テキストをトークンに分割する処理",
        "ユーザー認証を行うセキュリティ機能",
        "課金額を計算する料金計算システム",
        "出力結果を整形するフォーマッタ",
      ],
      correctIndex: 0,
      explanation:
        "トークナイザはテキストをモデルが処理可能なトークン単位に分割します。営業トーク例：「日本語に最適化されたトークナイザにより、効率的な処理とコスト削減を実現します」",
    },
    {
      id: "llm-27",
      question: "LLMにおける「Chain-of-Thought」とは何ですか？",
      options: [
        "段階的に推論過程を示す思考手法",
        "複数のモデルを連鎖させる技術",
        "会話履歴を保持するメモリ機能",
        "質問を連続して投げる対話方式",
      ],
      correctIndex: 0,
      explanation:
        "Chain-of-Thoughtは推論過程を段階的に示すことで精度を向上させる手法です。営業トーク例：「複雑な計算問題も、思考過程を明示することで正確な回答を導きます」",
    },
    {
      id: "llm-28",
      question: "LLMの「Function Calling」機能の用途はどれですか？",
      options: [
        "外部APIや関数との連携を実現する",
        "モデル内部の関数を直接呼び出す",
        "電話機能との連携を可能にする",
        "コールバック関数を登録する機能",
      ],
      correctIndex: 0,
      explanation:
        "Function Callingにより、LLMが外部APIやツールを呼び出して実行できます。営業トーク例：「予約システムやデータベースと連携し、実際の業務処理まで自動化できます」",
    },
    {
      id: "llm-29",
      question: "LLMにおける「top_p」パラメータの効果はどれですか？",
      options: [
        "出力候補の確率分布を制限して調整",
        "処理の優先度を最上位に設定する",
        "上位ランクのモデルを選択させる",
        "最も重要なトークンだけを出力する",
      ],
      correctIndex: 0,
      explanation:
        "top_p（nucleus sampling）は累積確率がpに達するまでの候補からサンプリングします。営業トーク例：「temperatureと組み合わせて、回答の一貫性と多様性を細かく調整できます」",
    },
    {
      id: "llm-30",
      question: "LLMの「コンテキスト学習」とは何ですか？",
      options: [
        "プロンプト内の情報から学習して応答",
        "周辺環境のデータを収集して学習",
        "ユーザーの行動履歴から学習する",
        "コンテキストメニューの使い方を学習",
      ],
      correctIndex: 0,
      explanation:
        "コンテキスト学習はプロンプトに含まれる例示や情報からタスクを理解する能力です。営業トーク例：「御社の過去のやり取り例を示すだけで、適切な対応方法を学習します」",
    },
    {
      id: "llm-31",
      question: "LLMの「プロンプトインジェクション」とは何ですか？",
      options: [
        "悪意ある入力でAIの動作を操作する攻撃",
        "プロンプトを効率的に圧縮する技術",
        "プロンプトを自動生成するツール名",
        "複数のプロンプトを結合する手法名",
      ],
      correctIndex: 0,
      explanation:
        "プロンプトインジェクションは悪意ある入力でAIを不正に操作する攻撃手法です。営業トーク例：「入力検証とサニタイズ処理で、プロンプトインジェクション対策を施しています」",
    },
    {
      id: "llm-32",
      question: "LLMにおける「RLHF」とは何ですか？",
      options: [
        "人間のフィードバックによる強化学習",
        "高速化された学習フレームワーク名",
        "ロジスティック回帰の学習手法名",
        "リアルタイム処理の最適化技術名",
      ],
      correctIndex: 0,
      explanation:
        "RLHFは人間のフィードバックを使った強化学習で、モデルを人間の好みに合わせます。営業トーク例：「人間のフィードバックで調整されているため、より自然で有用な回答を生成します」",
    },
    {
      id: "llm-33",
      question: "LLMの「オープンソースモデル」の利点はどれですか？",
      options: [
        "自社環境で自由にカスタマイズ可能",
        "常に最高精度が保証されている点",
        "セキュリティ対策が完全に不要",
        "利用料金が一切発生しない点",
      ],
      correctIndex: 0,
      explanation:
        "オープンソースLLMは自社サーバーで運用でき、カスタマイズの自由度が高いです。営業トーク例：「機密性の高いデータはオープンソースモデルを自社環境で運用する選択肢もあります」",
    },
    {
      id: "llm-34",
      question: "LLMにおける「quantization（量子化）」の目的はどれですか？",
      options: [
        "モデルサイズを圧縮して軽量化する",
        "量子コンピュータで実行可能にする",
        "精度を最大限に向上させる技術",
        "セキュリティを強化する暗号化手法",
      ],
      correctIndex: 0,
      explanation:
        "量子化はモデルの数値精度を下げてサイズを圧縮し、軽量化する技術です。営業トーク例：「量子化により、一般的なサーバーでも高性能LLMを効率的に運用できます」",
    },
    {
      id: "llm-35",
      question: "LLMの「ベクトルデータベース」との連携で可能になることはどれですか？",
      options: [
        "意味的に類似した文書の高速検索",
        "画像データの高品質な保存処理",
        "リアルタイム翻訳の精度向上",
        "音声認識の処理速度の向上",
      ],
      correctIndex: 0,
      explanation:
        "ベクトルデータベースにより埋め込みを使った意味検索が可能になります。営業トーク例：「社内文書をベクトル化することで、キーワード一致ではなく意味で検索できます」",
    },
    {
      id: "llm-36",
      question: "LLMを使った「チャットボット」構築で重要なことはどれですか？",
      options: [
        "対応範囲と限界を明確に設計する",
        "全ての質問に回答できるよう設計",
        "人間のオペレーターを完全に排除",
        "最大限の創造性を持たせる設計",
      ],
      correctIndex: 0,
      explanation:
        "チャットボットは対応範囲を明確にし、範囲外は人間に引き継ぐ設計が重要です。営業トーク例：「対応可能な質問と人間へのエスカレーション基準を明確に設計します」",
    },
    {
      id: "llm-37",
      question: "LLMの「文書要約」機能のビジネス活用例として適切なものはどれですか？",
      options: [
        "長い会議録を短時間で要点整理する",
        "要約文から元の文書を完全に復元",
        "全ての情報を漏れなく圧縮する処理",
        "複数言語の文書を統合して保存する",
      ],
      correctIndex: 0,
      explanation:
        "LLMの要約機能で長文の会議録やレポートを効率的に要点整理できます。営業トーク例：「毎日の会議録を自動要約し、重要な決定事項だけを抽出できます」",
    },
    {
      id: "llm-38",
      question: "LLMの「コード生成」機能の注意点として重要なものはどれですか？",
      options: [
        "生成コードの動作確認とレビュー必須",
        "生成コードは常に完璧で確認不要",
        "プログラマーが不要になること",
        "全てのプログラミング言語に非対応",
      ],
      correctIndex: 0,
      explanation:
        "LLMが生成したコードは動作確認とセキュリティレビューが必須です。営業トーク例：「コード生成を補助ツールとして活用し、開発者の生産性を向上させます」",
    },
    {
      id: "llm-39",
      question: "LLMの「バッチ処理」のユースケースとして適切なものはどれですか？",
      options: [
        "大量の文書を一括で分類処理する",
        "リアルタイムチャットの応答生成",
        "緊急の問い合わせへの即時対応",
        "ライブストリーミングの字幕生成",
      ],
      correctIndex: 0,
      explanation:
        "バッチ処理は大量の文書分類やデータ抽出など、即時性が不要な処理に適します。営業トーク例：「夜間バッチで翌日分の顧客メールを自動分類し、朝の対応を効率化できます」",
    },
    {
      id: "llm-40",
      question: "LLMの「パーソナライゼーション」で実現できることはどれですか？",
      options: [
        "ユーザー属性に応じた回答のカスタマイズ",
        "モデルの処理速度を個別に最適化する",
        "各ユーザー専用のモデルを作成する",
        "課金体系をユーザーごとに変更する",
      ],
      correctIndex: 0,
      explanation:
        "パーソナライゼーションによりユーザーの属性や履歴に基づいた回答を提供できます。営業トーク例：「顧客の業種や過去の問い合わせ履歴に基づいた最適な提案を自動生成します」",
    },
    {
      id: "llm-41",
      question: "LLMの「モデル比較」で評価すべき項目として適切なものはどれですか？",
      options: [
        "精度とコストと応答速度のバランス",
        "開発元企業の株価と時価総額のみ",
        "モデル名の知名度だけで判断する",
        "パラメータ数のみで比較すること",
      ],
      correctIndex: 0,
      explanation:
        "モデル比較では精度、コスト、速度、対応言語など複数の観点で評価します。営業トーク例：「御社の要件に基づき、複数モデルを比較検証して最適なものをご提案します」",
    },
    {
      id: "llm-42",
      question: "LLMの「日本語対応」で確認すべき点はどれですか？",
      options: [
        "日本語での精度と自然さの品質水準",
        "英語との翻訳機能のみで十分判断",
        "日本企業が開発したかどうかの点",
        "日本国内にサーバーがあるかの点",
      ],
      correctIndex: 0,
      explanation:
        "日本語対応モデルは文法の正確さ、敬語、専門用語の理解度を確認します。営業トーク例：「日本語に最適化されたモデルで、ビジネス敬語も正確に使いこなせます」",
    },
    {
      id: "llm-43",
      question: "LLMの「API利用」と「自社ホスティング」の比較で正しいものはどれですか？",
      options: [
        "APIは手軽で自社運用はカスタマイズ性高",
        "APIは常に高コストで自社運用が安価",
        "APIはセキュリティ低く自社運用が安全",
        "両者に違いはなく同じ結果が得られる",
      ],
      correctIndex: 0,
      explanation:
        "API利用は導入が容易で、自社ホスティングはカスタマイズ性と機密性が高いです。営業トーク例：「まずはAPI利用でスタートし、規模拡大時に自社運用を検討する段階的アプローチをご提案します」",
    },
    {
      id: "llm-44",
      question: "LLMの「コンプライアンス」対応で重要なことはどれですか？",
      options: [
        "データの保存場所と利用規約の確認",
        "最新モデルを常に使用し続けること",
        "コスト削減を最優先にした運用方針",
        "全ての機能を制限なく利用すること",
      ],
      correctIndex: 0,
      explanation:
        "LLM利用ではデータの取り扱いや保存場所が法規制に準拠しているか確認が必要です。営業トーク例：「GDPR等の規制に準拠したサービスで、コンプライアンス対応も万全です」",
    },
    {
      id: "llm-45",
      question: "LLMの「エラーハンドリング」で考慮すべきことはどれですか？",
      options: [
        "API障害時の代替手段とリトライ処理",
        "エラーは発生しないため考慮不要",
        "エラー時はシステム全体を停止する",
        "ユーザーに技術的エラー詳細を表示",
      ],
      correctIndex: 0,
      explanation:
        "LLM APIは障害が発生する可能性があり、リトライやフォールバック処理が重要です。営業トーク例：「障害発生時も業務継続できるよう、代替処理を組み込んだ堅牢な設計をご提供します」",
    },
    {
      id: "llm-46",
      question: "LLMの「プロンプトキャッシュ」の効果はどれですか？",
      options: [
        "同じ入力の再処理を省略しコスト削減",
        "プロンプトを永続的に保存する機能",
        "キャッシュメモリを増設して高速化",
        "過去のプロンプトを検索する機能",
      ],
      correctIndex: 0,
      explanation:
        "プロンプトキャッシュは同一のシステムプロンプトの再計算を省略してコストを削減します。営業トーク例：「プロンプトキャッシュにより、同じ設定での大量処理のコストを大幅に削減できます」",
    },
    {
      id: "llm-47",
      question: "LLMの「モデルのバージョン管理」が重要な理由はどれですか？",
      options: [
        "更新による挙動変化を把握して対応",
        "古いバージョンは自動的に削除される",
        "新バージョンは常に全面的に改善",
        "バージョンによる違いは存在しない",
      ],
      correctIndex: 0,
      explanation:
        "モデル更新で回答傾向が変わる可能性があり、バージョン固定や段階的移行が重要です。営業トーク例：「モデルバージョンを固定することで、安定した品質の回答を継続的に提供できます」",
    },
    {
      id: "llm-48",
      question: "LLMの「マルチターン対話」で重要なことはどれですか？",
      options: [
        "会話履歴を適切に管理してコンテキスト維持",
        "毎回新しい会話として処理すること",
        "ユーザーに毎回自己紹介を求めること",
        "一度の対話で全てを完結させること",
      ],
      correctIndex: 0,
      explanation:
        "マルチターン対話では会話履歴を保持し、文脈を理解した応答を生成します。営業トーク例：「会話の流れを記憶することで、自然な対話で複雑な問い合わせにも対応できます」",
    },
    {
      id: "llm-49",
      question: "LLMの「出力長制限」を設定する目的はどれですか？",
      options: [
        "コスト管理と適切な回答長の確保",
        "出力品質を最大化するための設定",
        "セキュリティを強化するための設定",
        "処理速度を低下させるための設定",
      ],
      correctIndex: 0,
      explanation:
        "出力長制限によりコストを管理し、用途に適した回答長を確保できます。営業トーク例：「FAQでは短く簡潔に、レポートでは詳細にと、用途に応じた出力長を設定できます」",
    },
    {
      id: "llm-50",
      question: "LLMの「将来性」について正しい認識はどれですか？",
      options: [
        "継続的な進化が期待され投資価値あり",
        "すでに技術は完成し進化は停止状態",
        "数年後には完全に廃れる一時的技術",
        "特定業界のみで使われる限定技術",
      ],
      correctIndex: 0,
      explanation:
        "LLMは急速に進化を続けており、ビジネスへの影響は今後も拡大が予想されます。営業トーク例：「今からLLM活用を始めることで、競合他社に先んじたデジタル変革を実現できます」",
    },
  ],
};
