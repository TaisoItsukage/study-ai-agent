# 大規模言語モデル（LLM）- 体系的学習テキスト

## はじめに

本テキストは、ChatGPTやClaudeなどの大規模言語モデル（LLM）について体系的に学ぶための教材です。LLMの仕組み、主要サービス、安全性、API利用、プロンプト設計、RAGなど、営業活動に必要な知識を網羅しています。

---

## 第1章：LLMの基本概念

### 1.1 LLMとは

**LLM（Large Language Model：大規模言語モデル）** とは、膨大なテキストデータで学習し、人間のような自然な文章を生成できるAIモデルです。

営業では「大規模言語モデル」と正式名称で説明すると、専門性をアピールできます。

### 1.2 文章生成の仕組み

LLMは「**次にどの単語が来る確率が高いか**」を予測することで文章を生成します。

- インターネットからリアルタイムで検索しているわけではない
- 学習したパターンから最も自然な言葉を選んでいる
- この仕組みを理解することで、情報の鮮度に関する誤解を防げる

### 1.3 主要な用語

#### トークン
テキストを処理する際の最小単位（単語や文字の塊）。

| 言語 | トークン数の目安 |
|------|-----------------|
| 英語 | 1単語 ≒ 約1トークン |
| 日本語 | 1文字 ≒ 約1〜2トークン |

料金は処理するトークン数で決まるため、見積もりの根拠として重要。

#### コンテキストウィンドウ
LLMが一度の会話で記憶・処理できるテキストの最大量（トークン数）。

- 例：「128Kトークン対応」= 長文ドキュメントや長い会話履歴を扱える
- お客様の用途に応じて適切なコンテキストウィンドウを持つモデルを提案

#### パラメータ数
モデルが持つ学習可能な変数の数。

- 一般的にパラメータ数が多いほど複雑なタスクを処理可能
- ただし計算コストも増加
- 「パラメータ数が多い＝高性能」と単純化せず、用途に適したモデル選びが重要

### 1.4 学習と推論

#### 事前学習（Pre-training）
大量のテキストデータでモデルの基礎能力を学習させるプロセス。
- 文法、知識、推論能力などを獲得
- 「基礎教育を受けた状態のAI」と例えると分かりやすい

#### 推論（Inference）
学習済みモデルを使ってユーザーの質問に回答を生成する処理。
- API利用料金は主にこの推論処理に対して発生
- 「学習は開発会社が行い、お客様は推論（利用）部分の料金を払う」

#### 知識のカットオフ
学習データの収集が終了した日付。それ以降の情報は回答できない。
- 最新情報にはRAGやウェブ検索機能の併用が有効

### 1.5 技術的基盤

#### Transformerアーキテクチャ
Googleが2017年に発表した深層学習アーキテクチャで、GPTやClaudeなど現代のLLMの基盤。

#### Attention機構
入力テキストの各部分がどの程度関連しているかを計算し、重要な情報に注目して処理する仕組み。
- 長文でも文脈を正確に理解可能
- 「人間が文章を読むとき重要な部分に注目するのと同じ原理」

#### ベクトル
単語や文章を数百〜数千次元の数値配列として表現したもの。
- 意味の近い言葉は近いベクトルになる
- 類似検索やRAGが可能な理由

#### エンベディング（Embedding）
テキストを意味を保持した数値ベクトルに変換する技術。
- RAGやセマンティック検索の基盤技術
- 「似た意味の文章を探し出す技術の基盤」

#### トークナイザー
入力テキストをトークンに分割するプログラム。
- モデルごとにトークナイザーが異なる
- 同じ文章でもモデルによってトークン数が変わる

### 1.6 学習手法

#### ゼロショット学習
例を示さずに指示だけでタスクを実行させること。
- 追加の学習データなしで様々なタスクに対応可能

#### フューショット学習
プロンプト内に数個の入出力例を示してタスクを実行させる手法。
- 業務に合わせた例を用意することで精度が大幅に向上

### 1.7 性能指標

| 指標 | 説明 |
|------|------|
| **レイテンシー** | 質問を送信してから回答が返ってくるまでの応答時間 |
| **スループット** | 単位時間あたりに処理できるリクエスト数やトークン数 |

---

## 第2章：主要なLLMサービス

### 2.1 主要企業とモデル

| 企業 | 主要モデル | 特徴 |
|------|-----------|------|
| **OpenAI** | GPT-4, GPT-3.5, o1 | ChatGPTの開発元、最も広く使用 |
| **Anthropic** | Claude 3 (Opus/Sonnet/Haiku) | 安全性研究に注力、AWS連携 |
| **Google** | Gemini | Google Workspace/Cloud連携が強み |
| **Meta** | LLaMA | オープンソース、自社運用可能 |
| **Mistral AI** | Mistral | フランス発、EU対応に強み |

### 2.2 OpenAIモデルの詳細

#### GPT（Generative Pre-trained Transformer）
「生成的事前学習Transformer」の略。

#### GPT-4 vs GPT-3.5
- GPT-4は推論能力、正確性、安全性が向上
- より複雑なタスクに対応可能だが料金も高い
- シンプルなタスクにはGPT-3.5で十分な場合も

#### GPT-4 Turbo
- 知識のカットオフが新しい
- 128Kトークンの大きなコンテキストウィンドウ
- 料金がGPT-4より安い

#### o1（OpenAI o1）
- 「thinking（思考）」機能を持つ
- 複雑な推論、数学、科学、コーディングに強い
- 応答時間が長く、料金も高い

### 2.3 Claude 3シリーズ

| モデル | 特徴 |
|--------|------|
| **Opus** | 最高性能、複雑な分析向け |
| **Sonnet** | バランス型 |
| **Haiku** | 軽量・高速・低コスト、日常タスク向け |

### 2.4 エンタープライズサービス

#### Azure OpenAI Service
- MicrosoftのAzure上でGPTモデルを利用
- エンタープライズ向けセキュリティ、コンプライアンス基準を満たす
- 既存のAzure環境と統合可能

#### Amazon Bedrock
- AWS上で複数のLLM（Claude、Titan、LLaMAなど）を選択・利用可能
- 既存AWS環境との統合が容易

#### Google Vertex AI
- Geminiなどのモデルを利用・カスタマイズ可能
- BigQueryなどとのデータ連携に強み

### 2.5 その他のサービス

#### ChatGPT Plus
- 月額課金の個人向けプラン
- GPT-4、DALL-E、コード実行などの高度な機能

#### ChatGPT Enterprise
- 企業向けにセキュリティ強化・管理機能・無制限利用を提供
- SOC 2準拠、SSO対応

#### Microsoft Copilot
- GPT技術を活用したAIアシスタント
- Word、Excel、Teams、Windowsなどに統合

#### GitHub Copilot
- プログラミング支援AI
- コードの自動補完や提案

#### Perplexity
- AI検索エンジン
- 情報源を明示しながら回答
- 最新情報へのアクセスとハルシネーション軽減

### 2.6 日本語特化モデル

- **ELYZA**（PKSHA/東京大学発）
- **PLaMo**（Preferred Networks）
- **Japanese StableLM**（Stability AI Japan）

日本語特有のニュアンスや敬語表現を重視するお客様に提案可能。

### 2.7 オープンソースLLMの利点

- 自社環境でモデルを運用可能
- データを外部に送信せずに済む
- ただし運用には技術力が必要
- データセキュリティ要件の厳しいお客様に提案可能

---

## 第3章：ハルシネーションと安全性

### 3.1 ハルシネーション（AI幻覚）

LLMが事実ではない情報をあたかも本当のことのように自信を持って回答してしまう現象。

#### 特に問題になる業界
- 医療・法律・金融など正確性が重要な業界
- 「AIは補助ツールとして使用し、専門家が必ず確認する」運用を推奨

#### 軽減方法
**RAG（検索拡張生成）** で外部知識を参照させることが最も効果的。

### 3.2 バイアス問題

学習データに含まれる社会的バイアス（性別、人種、文化的偏見など）がAIの出力に反映される可能性。
- 採用支援や審査業務では特に注意
- バイアスの検証と人間によるチェック体制が重要

### 3.3 安全性向上の技術

#### RLHF（Reinforcement Learning from Human Feedback）
人間のフィードバックによる強化学習。人間の評価者がAIの回答を評価し、改善に活用。

#### Constitutional AI
Anthropicが開発した手法。AIに原則（憲法）を与え、自己批判・改善させる。

#### レッドチーミング
専門家が意図的にAIシステムを攻撃・悪用しようとして、脆弱性を発見するテスト。

### 3.4 セキュリティの脅威

#### ジェイルブレイク
安全対策を回避して有害な出力を引き出そうとする攻撃手法。
- セキュリティ対策済みのエンタープライズ版の利用を推奨

#### プロンプトインジェクション
悪意ある指示を入力に紛れ込ませ、AIの動作を操作しようとする攻撃。
- 入力の検証やサンドボックス化などの対策が必要

#### コンテンツフィルタリング
有害・不適切なコンテンツの入出力を検知・ブロックする機能。

### 3.5 データプライバシー

- APIに送信したデータは利用規約によってはモデル改善に使用される可能性
- 機密情報を扱う場合は、データが学習に使用されないプランやオンプレミス環境を検討

### 3.6 著作権

学習データに含まれるコンテンツを大量にそのまま出力する場合、著作権侵害の可能性。
- AI生成物の商用利用時は権利関係の確認が必要

### 3.7 説明責任

- AIの判断根拠を可能な限り明示
- 人間が最終判断する体制を構築
- 「AIは参考意見を提供し、人間が最終判断する」運用

### 3.8 モデルカード

AIモデルの性能、限界、倫理的考慮事項などを記載した文書。責任あるAI開発の一環として公開。

### 3.9 EU AI Act

LLMなどの汎用AIシステムは透明性要件（技術文書の作成、EU法への準拠など）が課される。

---

## 第4章：料金体系とAPI

### 4.1 基本的な料金体系

多くのLLM APIは**処理したトークン数に応じた従量課金制**。

| 種類 | 説明 |
|------|------|
| **入力トークン** | ユーザーが送信するテキストの量 |
| **出力トークン** | AIが生成する回答の量（通常こちらが高額） |

### 4.2 利用制限

| 指標 | 説明 |
|------|------|
| **RPM** | Requests Per Minute（1分あたりのAPI呼び出し回数制限） |
| **TPM** | Tokens Per Minute（1分あたりの処理トークン数制限） |

#### OpenAI APIのTier
過去の利用金額や支払い実績に応じた利用制限のレベル。Tierが上がると制限が緩和。

### 4.3 APIの機能

#### ストリーミングレスポンス
回答を生成しながら少しずつ返す方式。体感待ち時間を短縮。

#### バッチAPI
大量のリクエストを非同期でまとめて処理。料金が割安（OpenAIでは50%オフ）。

#### Function Calling
LLMが外部の関数やAPIを呼び出すタイミングと引数を判断する機能。

#### JSON Mode
LLMの出力を必ずJSON形式にする設定。システム連携で必須。

#### Assistants API
会話履歴の管理、ファイル処理、ツール実行などの機能を統合的に提供。

### 4.4 セキュリティと管理

#### APIキーの管理
- 公開リポジトリやフロントエンドコードに含めない
- 環境変数やシークレット管理サービスを利用

#### コスト上限設定
予期せぬ大量利用による高額請求を防ぐために必須。

### 4.5 エラー処理

#### レート制限エラー（429エラー）
**指数バックオフ**（1秒、2秒、4秒...と待ち時間を延ばしながら再試行）を実装。

### 4.6 コスト最適化

| 手法 | 説明 |
|------|------|
| **キャッシング** | 同じ質問への回答を保存し再利用 |
| **モデル選択** | タスクに応じて適切なモデルを使い分け |
| **バッチAPI** | 即時性が不要な大量処理に使用 |
| **Embedding API** | Chat APIより安価、検索処理に使用 |

### 4.7 SLA（Service Level Agreement）

主に稼働率（例：99.9%）やサポート対応時間が保証される。回答精度は保証対象外。

### 4.8 ファインチューニングの料金

- 学習時の料金
- ファインチューニングモデル使用時の推論料金（通常より高い）
- 両方を考慮した見積もりが必要

---

## 第5章：プロンプトエンジニアリング

### 5.1 プロンプトとは

LLMに対して送る入力文（質問、指示、文脈情報など）。プロンプトの書き方で回答の質が大きく変わる。

### 5.2 システムプロンプト

AIの役割や振る舞いのルールを設定するプロンプト。
- 「あなたは〇〇の専門家です」
- 「丁寧な敬語で回答してください」

### 5.3 効果的なプロンプトの書き方

| 要素 | 説明 |
|------|------|
| **具体的な指示** | 何をしてほしいかを明確に |
| **期待する出力形式** | 箇条書き、JSON形式など |
| **必要な文脈** | 背景情報を提供 |

悪い例：「分かりやすく説明して」
良い例：「初心者向けに3つのポイントで説明して」

### 5.4 プロンプト技法

#### Chain of Thought（思考の連鎖）
「ステップバイステップで考えてください」と指示し、AIに推論過程を明示させる。
- 数学問題や論理的推論で精度向上

#### ロールプレイ
AIに特定の役割や専門家を演じさせる。
- 「あなたは10年経験のあるマーケティング専門家です」

#### 制約条件
出力の形式や内容を制御。
- 「100文字以内で」「専門用語を使わずに」「箇条書きで3点」

#### ネガティブプロンプト
「〜しないでください」「〜を含めないでください」と避けてほしい行動を明示。

### 5.5 プロンプト構造

#### デリミター
プロンプト内の異なるセクションを区切る記号。
- 例：「###指示###」「```入力データ```」
- AIがプロンプトの構造を正確に理解しやすくなる

#### プロンプトテンプレート
変数部分を埋め込むだけで使えるプロンプトの雛形。
- チーム全体で品質を統一
- 作成効率向上

#### プロンプトチェーン
複数のプロンプトを連続して実行し、前の出力を次の入力に使う。
- 複雑なタスクを分解して精度向上

### 5.6 プロンプトの最適化

A/Bテストで複数のプロンプトを比較し、継続的に改善することが重要。

### 5.7 プロンプトエンジニアリングの価値

追加開発なしでAIの効果を最大化できる手法。導入コストを抑えつつ効果を出したいお客様に有効。

---

## 第6章：ファインチューニング

### 6.1 ファインチューニングとは

事前学習済みモデルを特定のデータで追加学習させること。

- 独自の文体
- 専門知識
- 特定のタスクへの対応力向上

### 6.2 有効なケース

- 独自の文体やフォーマットで一貫した出力が必要
- 企業のトーン&マナーに沿った文章生成
- 専門用語の正確な使用

### 6.3 ファインチューニング vs プロンプトエンジニアリング

| 項目 | ファインチューニング | プロンプトエンジニアリング |
|------|---------------------|--------------------------|
| コスト | 高い | 低い |
| 時間 | かかる | すぐ始められる |
| 効果 | モデル自体を変更 | 入力の工夫 |
| 推奨 | まずプロンプトから始め、必要に応じてファインチューニング |

### 6.4 LoRA（Low-Rank Adaptation）

少ないパラメータで効率的にファインチューニングを行う手法。
- 学習コストとストレージを大幅に削減
- 複数の用途向けモデルを低コストで運用可能

### 6.5 データ準備

高品質で一貫性のある入出力ペア（質問と理想的な回答のセット）を十分な量用意することが成功の鍵。

---

## 第7章：RAG（検索拡張生成）

### 7.1 RAGとは

**RAG（Retrieval-Augmented Generation）** は、質問に関連する情報を外部データベースや文書から検索し、その情報をコンテキストとしてLLMに渡すことで、正確で最新の情報に基づいた回答を生成する手法。

### 7.2 RAGの利点

- ハルシネーションの大幅軽減
- 最新情報への対応
- 頻繁な情報更新に強い
- 社内文書を活用したAIチャットボットの基盤技術

### 7.3 RAG vs ファインチューニング

| 項目 | RAG | ファインチューニング |
|------|-----|---------------------|
| 得意 | 最新情報、頻繁な更新 | 一貫した文体、フォーマット |
| 仕組み | 外部データ参照 | モデル自体の変更 |

両方の組み合わせも可能。

### 7.4 RAGシステムの構成要素

#### ベクトルデータベース
テキストのベクトル（埋め込み）を保存し、類似度検索を高速に行う。
- 例：Pinecone、Weaviate、Chroma

#### チャンク
長い文書を検索に適したサイズに分割した断片。
- 小さすぎると文脈が失われる
- 大きすぎると関連性の低い情報が含まれる

### 7.5 検索精度向上

#### ハイブリッド検索
ベクトル検索（意味の類似性）とキーワード検索を組み合わせる手法。

#### リランキング
最初の検索結果を別のモデルで再評価し、より関連性の高い順に並べ替える。

---

## 第8章：マルチモーダルAI

### 8.1 マルチモーダルAIとは

テキストだけでなく、画像、音声、動画など複数の種類（モダリティ）のデータを理解・生成できるAI。

対応モデル：GPT-4V、Gemini、Claude 3など

### 8.2 GPT-4Vの「V」

Vision（視覚・画像理解）を意味し、画像を入力として受け取り、内容を理解・説明できる。

### 8.3 ビジネス活用例

- 製品画像からの説明文自動生成
- 手書きメモや名刺のデジタル化
- 図面や設計図の解析
- 医療画像の説明

### 8.4 注意点

- 機密文書の画像の取り扱い
- 個人情報を含む写真
- 著作権のある画像
- 画像処理は通常のテキスト処理より料金が高い場合が多い

---

## 第9章：出力制御パラメータ

### 9.1 Temperature（温度）

出力のランダム性・創造性を制御するパラメータ。

| 値 | 特徴 | 用途 |
|-----|------|------|
| 0〜0.3 | 一貫した確定的な出力 | 事実確認、ビジネス文書 |
| 0.7〜0.9 | 多様で創造的な出力 | 創作、アイデア出し |

### 9.2 Top-P（Nucleus Sampling）

累積確率がPに達するまでの単語候補から選択する方式。
- 0.1なら上位10%の確率の単語から選択
- Temperatureと組み合わせて出力の多様性を制御

### 9.3 用途別推奨設定

| 用途 | Temperature |
|------|-------------|
| FAQ回答、ビジネス文書 | 0.3〜0.5 |
| マーケティングコピー、アイデア出し | 0.7〜0.9 |

---

## 第10章：導入成功のポイント

### 10.1 成功のアプローチ

1. **明確なユースケースの特定**
   - 例：カスタマーサポート、文書要約

2. **小規模なPoC（概念実証）から開始**
   - 効果を検証

3. **段階的な拡大**
   - 成功を確認しながら展開

### 10.2 営業での提案

「一緒に最適な導入計画を策定しましょう」と提案し、伴走型の支援を提供。

---

## 第11章：用語集

| 用語 | 説明 |
|------|------|
| LLM | Large Language Model（大規模言語モデル） |
| GPT | Generative Pre-trained Transformer |
| トークン | テキスト処理の最小単位 |
| コンテキストウィンドウ | 一度に処理できるテキストの最大量 |
| ハルシネーション | 事実と異なる情報を生成する現象 |
| RAG | Retrieval-Augmented Generation（検索拡張生成） |
| RLHF | 人間のフィードバックによる強化学習 |
| エンベディング | テキストをベクトルに変換する技術 |
| ファインチューニング | モデルを追加学習させること |
| Temperature | 出力のランダム性を制御するパラメータ |

---

## まとめ

LLMの知識は、以下の観点で整理できます：

1. **基本概念**：トークン、コンテキストウィンドウ、推論、Transformer
2. **主要サービス**：OpenAI、Anthropic、Google、Meta、エンタープライズ版
3. **安全性**：ハルシネーション、バイアス、セキュリティ対策
4. **料金・API**：従量課金、制限、Function Calling、JSON Mode
5. **プロンプト**：システムプロンプト、CoT、テンプレート
6. **カスタマイズ**：ファインチューニング、RAG、LoRA
7. **マルチモーダル**：画像理解、複数モダリティ対応
8. **パラメータ**：Temperature、Top-P

これらの知識を活用し、お客様の要件に最適なLLMソリューションを提案しましょう。
