import { Genre } from "../types";

export const llm: Genre = {
  id: "llm",
  name: "大規模言語モデル (LLM)",
  description: "ChatGPTやClaudeなどの大規模言語モデルの仕組みと特徴を学びます。最も注目されているAI技術の基礎を理解しましょう。",
  icon: "💬",
  questions: [
    // === LLMの基本概念（1-20） ===
    {
      id: "llm-001",
      question: "LLMは何の略称ですか？",
      options: [
        "Large Language Model",
        "Learning Language Machine",
        "Logical Language Method",
        "Limited Language Module"
      ],
      correctIndex: 0,
      explanation: "LLMは「Large Language Model（大規模言語モデル）」の略です。膨大なテキストデータで学習し、人間のような自然な文章を生成できるAIモデルのことを指します。営業では「大規模言語モデル」と正式名称で説明すると、専門性をアピールできます。"
    },
    {
      id: "llm-002",
      question: "LLMが文章を生成する基本的な仕組みはどれですか？",
      options: [
        "インターネットからリアルタイムで文章を検索してコピー",
        "次に来る可能性が高い単語を予測して順番に生成する",
        "あらかじめ用意された文章テンプレートを選択して出力",
        "人間のオペレーターが裏で文章を作成して返答する"
      ],
      correctIndex: 1,
      explanation: "LLMは「次にどの単語が来る確率が高いか」を予測することで文章を生成します。お客様には「AIが学習したパターンから最も自然な言葉を選んでいる」と説明すると理解されやすいです。リアルタイム検索ではないことを伝えることで、情報の鮮度に関する誤解も防げます。"
    },
    {
      id: "llm-003",
      question: "「トークン」とはLLMにおいて何を指しますか？",
      options: [
        "AIサービスの利用料金の単位のこと",
        "テキストを処理する際の最小単位（単語や文字の塊）",
        "AIモデルのセキュリティ認証キーのこと",
        "ユーザーのログイン情報のこと"
      ],
      correctIndex: 1,
      explanation: "トークンは、LLMがテキストを処理する際の最小単位です。英語では1単語が約1トークン、日本語では1文字が約1〜2トークンになります。営業時には「料金は処理するテキストの量（トークン数）で決まります」と説明し、見積もりの根拠として活用しましょう。"
    },
    {
      id: "llm-004",
      question: "「コンテキストウィンドウ」とは何を指しますか？",
      options: [
        "AIが表示されるブラウザの画面サイズのこと",
        "AIが一度に処理できるテキストの最大量",
        "AIの応答が表示されるウィンドウのこと",
        "AIの設定画面のことを指す用語"
      ],
      correctIndex: 1,
      explanation: "コンテキストウィンドウは、LLMが一度の会話で記憶・処理できるテキストの最大量（トークン数）を指します。例えば「128Kトークン対応」は、長文ドキュメントや長い会話履歴を扱えることを意味します。お客様の用途に応じて、適切なコンテキストウィンドウを持つモデルを提案しましょう。"
    },
    {
      id: "llm-005",
      question: "LLMの「パラメータ数」が大きいとどのような傾向がありますか？",
      options: [
        "処理速度が速くなる傾向がある",
        "より複雑なタスクを処理できる可能性が高まる",
        "消費電力が減る傾向がある",
        "料金が安くなる傾向がある"
      ],
      correctIndex: 1,
      explanation: "パラメータ数は、モデルが持つ学習可能な変数の数です。一般的にパラメータ数が多いほど複雑なタスクを処理できますが、計算コストも増加します。営業では「パラメータ数が多い＝高性能」と単純化せず、用途に適したモデル選びが重要と伝えましょう。"
    },
    {
      id: "llm-006",
      question: "「事前学習（Pre-training）」とは何ですか？",
      options: [
        "ユーザーが使用前に行う設定作業のこと",
        "大量のテキストデータでモデルの基礎能力を学習させること",
        "AIを使う前のテスト運用期間のこと",
        "営業担当者向けの研修プログラムのこと"
      ],
      correctIndex: 1,
      explanation: "事前学習は、インターネット上の大量のテキストデータを使ってLLMに言語の基礎を学習させるプロセスです。この段階で文法、知識、推論能力などを獲得します。お客様には「基礎教育を受けた状態のAI」と例えると分かりやすいです。"
    },
    {
      id: "llm-007",
      question: "LLMの「推論（Inference）」とは何ですか？",
      options: [
        "AIが新しい知識を学習すること",
        "学習済みモデルを使ってユーザーの質問に回答を生成すること",
        "AIが自分の間違いを修正すること",
        "AIが他のAIと通信すること"
      ],
      correctIndex: 1,
      explanation: "推論は、学習済みのLLMが実際にユーザーの入力に対して回答を生成する処理です。API利用料金は主にこの推論処理に対して発生します。営業では「学習は開発会社が行い、お客様は推論（利用）部分の料金を払う」と説明しましょう。"
    },
    {
      id: "llm-008",
      question: "「Transformer」アーキテクチャとは何ですか？",
      options: [
        "変形するロボットの設計図のこと",
        "現代のLLMの基盤となる深層学習の構造",
        "電力を変換する装置のことを指す",
        "データ形式を変換するツールのこと"
      ],
      correctIndex: 1,
      explanation: "TransformerはGoogleが2017年に発表した深層学習アーキテクチャで、GPTやClaudeなど現代のLLMの基盤です。Attention機構により文章全体の関係性を効率的に捉えられます。技術的な質問には「最先端のTransformer技術を採用」と答えられると信頼感が増します。"
    },
    {
      id: "llm-009",
      question: "LLMにおける「Attention機構」の役割は何ですか？",
      options: [
        "ユーザーの注意を引くための機能のこと",
        "入力文の各部分の重要度を判断し、関連性の高い情報に注目する仕組み",
        "AIが疲れないように休憩を入れる機能のこと",
        "長文を短く要約する機能のこと"
      ],
      correctIndex: 1,
      explanation: "Attention機構は、入力テキストの各部分がどの程度関連しているかを計算し、重要な情報に注目して処理する仕組みです。これにより長文でも文脈を正確に理解できます。お客様には「人間が文章を読むとき重要な部分に注目するのと同じ原理」と説明できます。"
    },
    {
      id: "llm-010",
      question: "「ベクトル」とはLLMにおいて何を表しますか？",
      options: [
        "AIの移動方向を示すもの",
        "単語や文章を数値の配列として表現したもの",
        "ウイルス対策機能を指すもの",
        "グラフィック画像の種類のこと"
      ],
      correctIndex: 1,
      explanation: "ベクトルは、単語や文章の意味を数百〜数千次元の数値配列として表現したものです。意味の近い言葉は近いベクトルになります。営業では「AIは言葉を数値に変換して計算している」と説明することで、なぜ類似検索やRAGが可能かを説明できます。"
    },
    {
      id: "llm-011",
      question: "「エンベディング（Embedding）」とは何ですか？",
      options: [
        "AIをシステムに組み込むこと",
        "テキストを意味を保持した数値ベクトルに変換すること",
        "画像をテキストに変換すること",
        "データを圧縮することである"
      ],
      correctIndex: 1,
      explanation: "エンベディングは、テキストをその意味を表す数値ベクトルに変換する技術です。RAG（検索拡張生成）やセマンティック検索の基盤技術です。お客様には「似た意味の文章を探し出す技術の基盤」と説明し、社内文書検索などの活用例を提案できます。"
    },
    {
      id: "llm-012",
      question: "LLMの「学習データ」に関する説明として正しいものはどれですか？",
      options: [
        "ユーザーとの会話は全て学習データとして使用されている",
        "インターネット上の書籍、ウェブサイト、論文などの大量のテキストが使用される",
        "学習データは完全に公開されていて誰でも確認可能",
        "学習データは常にリアルタイムで更新されている"
      ],
      correctIndex: 1,
      explanation: "LLMは主にインターネット上の公開テキストデータで学習されています。ただし、具体的なデータセットは各社で異なり、ユーザーの会話データの扱いも利用規約によって異なります。お客様のデータプライバシーへの懸念には、各サービスの利用規約を確認することを勧めましょう。"
    },
    {
      id: "llm-013",
      question: "「知識のカットオフ」とは何を意味しますか？",
      options: [
        "AIの知識を制限することを指す",
        "学習データの収集が終了した時点以降の情報をAIが持っていないこと",
        "ユーザーの質問を途中で打ち切ることを指す",
        "AIの利用時間制限のことを指す"
      ],
      correctIndex: 1,
      explanation: "知識のカットオフは、LLMの学習データ収集が終了した日付を指します。例えば2023年4月がカットオフの場合、それ以降のニュースや出来事については回答できません。営業では「最新情報にはRAGやウェブ検索機能の併用が有効」と提案できます。"
    },
    {
      id: "llm-014",
      question: "LLMの「レイテンシー」とは何を指しますか？",
      options: [
        "AIの学習にかかる時間のこと",
        "ユーザーの入力から回答が返ってくるまでの待ち時間",
        "AIの利用可能時間のことを指す",
        "契約期間のことを指す用語"
      ],
      correctIndex: 1,
      explanation: "レイテンシーは、質問を送信してから回答が返ってくるまでの応答時間です。リアルタイム性が求められるチャットボットでは重要な指標です。営業では「平均応答時間は○秒程度」と具体的な数値を示すと説得力が増します。"
    },
    {
      id: "llm-015",
      question: "「スループット」とは何を指しますか？",
      options: [
        "AIの精度を表す指標",
        "単位時間あたりに処理できるリクエスト数やトークン数",
        "AIの学習速度を表す指標",
        "ユーザー満足度を表す指標"
      ],
      correctIndex: 1,
      explanation: "スループットは、LLMが単位時間あたりに処理できるリクエスト数やトークン数を表します。大量のリクエストを処理する業務では重要な指標です。お客様の利用規模を確認し、必要なスループットを満たすプランを提案しましょう。"
    },
    {
      id: "llm-016",
      question: "「入力トークン」と「出力トークン」の違いは何ですか？",
      options: [
        "違いはなく同じものを指す用語である",
        "入力トークンはユーザーの質問、出力トークンはAIの回答の長さを表す",
        "入力トークンは暗号化前、出力トークンは暗号化後のデータのこと",
        "入力トークンはAPIキー、出力トークンはアクセストークンのこと"
      ],
      correctIndex: 1,
      explanation: "入力トークンはユーザーがAIに送信するテキストの量、出力トークンはAIが生成する回答の量を表します。多くのAPIでは両方に対して課金され、出力トークンの方が高額な場合が多いです。コスト見積もりでは両方を考慮しましょう。"
    },
    {
      id: "llm-017",
      question: "LLMの「ファインチューニング」と「プロンプトエンジニアリング」の違いは何ですか？",
      options: [
        "同じことを指す別の言い方である",
        "ファインチューニングはモデル自体を再学習、プロンプトは入力文の工夫",
        "ファインチューニングは無料、プロンプトは有料である",
        "ファインチューニングはAPI、プロンプトはUIを指す"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは特定のデータでモデル自体を追加学習させる手法で、コストと時間がかかります。プロンプトエンジニアリングは入力文の工夫で望む出力を得る手法で、手軽に始められます。まずはプロンプトの工夫から始め、必要に応じてファインチューニングを提案しましょう。"
    },
    {
      id: "llm-018",
      question: "「ゼロショット学習」とは何ですか？",
      options: [
        "学習なしでAIを使うことを指す",
        "例を示さずに指示だけでタスクを実行させること",
        "無料でAIを使うことを指す",
        "エラーなしで処理することを指す"
      ],
      correctIndex: 1,
      explanation: "ゼロショット学習は、具体的な例を示さずに指示文だけでLLMにタスクを実行させることです。LLMは事前学習で獲得した知識を活用して対応します。営業では「追加の学習データなしで様々なタスクに対応できる」という利点として説明できます。"
    },
    {
      id: "llm-019",
      question: "「フューショット学習」とは何ですか？",
      options: [
        "少ない計算で学習することを指す",
        "プロンプト内に数個の例を示してタスクを実行させること",
        "撮影しながら学習することを指す",
        "短時間で学習を完了することを指す"
      ],
      correctIndex: 1,
      explanation: "フューショット学習は、プロンプト内に数個の入出力例を示すことで、LLMにタスクの期待する形式や内容を理解させる手法です。お客様の業務に合わせた例を用意することで、精度を大幅に向上させられます。導入支援時の具体的なテクニックとして提案しましょう。"
    },
    {
      id: "llm-020",
      question: "LLMにおける「トークナイザー」の役割は何ですか？",
      options: [
        "料金を計算するプログラムのこと",
        "テキストをトークンに分割するプログラム",
        "ユーザー認証を行うプログラムのこと",
        "データを暗号化するプログラムのこと"
      ],
      correctIndex: 1,
      explanation: "トークナイザーは、入力テキストをLLMが処理できるトークンに分割するプログラムです。モデルごとにトークナイザーが異なるため、同じ文章でもトークン数が変わることがあります。料金計算の際は、使用するモデルのトークナイザーで確認することを勧めましょう。"
    },

    // === 主要なLLMサービス（21-40） ===
    {
      id: "llm-021",
      question: "ChatGPTを開発した企業はどこですか？",
      options: [
        "Google",
        "Microsoft",
        "OpenAI",
        "Meta"
      ],
      correctIndex: 2,
      explanation: "ChatGPTはOpenAIが開発しました。MicrosoftはOpenAIに大規模投資を行っており、Azure OpenAI ServiceとしてChatGPTの技術を提供しています。競合他社の関係性を理解しておくと、お客様の既存環境に合わせた提案ができます。"
    },
    {
      id: "llm-022",
      question: "Claudeを開発した企業はどこですか？",
      options: [
        "OpenAI",
        "Anthropic",
        "Google",
        "Amazon"
      ],
      correctIndex: 1,
      explanation: "ClaudeはAnthropicが開発しました。AnthropicはOpenAIの元メンバーが設立した企業で、AIの安全性研究に力を入れています。Amazon Web Services（AWS）と提携しており、AWS経由での利用も可能です。お客様のクラウド環境に応じた提案が可能です。"
    },
    {
      id: "llm-023",
      question: "GeminiはどのIT企業が開発したLLMですか？",
      options: [
        "Microsoft",
        "Google",
        "Apple",
        "OpenAI"
      ],
      correctIndex: 1,
      explanation: "GeminiはGoogleが開発したLLMで、Google WorkspaceやGoogle Cloudとの連携が強みです。既にGoogleのサービスを利用しているお客様には、Geminiの導入がスムーズになる可能性があることを提案できます。"
    },
    {
      id: "llm-024",
      question: "LLaMA（ラマ）を開発した企業はどこですか？",
      options: [
        "OpenAI",
        "Google",
        "Meta（旧Facebook）",
        "Microsoft"
      ],
      correctIndex: 2,
      explanation: "LLaMAはMeta（旧Facebook）が開発したオープンソースのLLMです。研究目的で公開され、多くの派生モデルが生まれました。オープンソースモデルを自社サーバーで運用したいお客様には、LLaMAベースのソリューションを検討できます。"
    },
    {
      id: "llm-025",
      question: "GPT-4とGPT-3.5の主な違いは何ですか？",
      options: [
        "GPT-4の方が料金が安い",
        "GPT-4は推論能力が高く、より複雑なタスクに対応できる",
        "GPT-3.5の方がモデルとして新しい",
        "GPT-4は英語のみの対応となっている"
      ],
      correctIndex: 1,
      explanation: "GPT-4はGPT-3.5より推論能力、正確性、安全性が向上しており、より複雑なタスクに対応できます。ただし料金も高くなります。営業では、お客様の要件と予算に応じてモデルを使い分ける提案が有効です。シンプルなタスクにはGPT-3.5で十分な場合もあります。"
    },
    {
      id: "llm-026",
      question: "Azure OpenAI Serviceの特徴として正しいものはどれですか？",
      options: [
        "OpenAIより安い料金でGPTモデルを使えること",
        "企業向けセキュリティ基準でGPTを利用できる",
        "GPTより高性能な独自モデルを使えること",
        "無料で利用できるサービスであること"
      ],
      correctIndex: 1,
      explanation: "Azure OpenAI Serviceは、MicrosoftのAzure上でGPTモデルを利用できるサービスです。エンタープライズ向けのセキュリティ、コンプライアンス基準を満たし、既存のAzure環境と統合できます。セキュリティ要件の厳しい企業には特に有効な選択肢として提案できます。"
    },
    {
      id: "llm-027",
      question: "Amazon Bedrockとは何ですか？",
      options: [
        "Amazonが独自に開発したLLMのこと",
        "AWS上で複数のLLMを利用できるサービス",
        "Amazonの商品推薦用のAIシステム",
        "AWSのサーバーハードウェアのこと"
      ],
      correctIndex: 1,
      explanation: "Amazon Bedrockは、Claude、Titan、LLaMAなど複数のLLMをAWS上で選択・利用できるマネージドサービスです。既にAWSを利用しているお客様には、既存環境との統合が容易であることを強調できます。"
    },
    {
      id: "llm-028",
      question: "Google Vertex AIの特徴は何ですか？",
      options: [
        "Googleが提供する無料のLLMサービス",
        "Geminiなどを利用できるMLプラットフォーム",
        "ゲーム開発に特化したAIサービス",
        "個人ユーザー向けの簡易AIツール"
      ],
      correctIndex: 1,
      explanation: "Vertex AIはGoogleの機械学習プラットフォームで、Geminiなどのモデルを利用・カスタマイズできます。Google Cloudの他のサービスとの連携も容易です。BigQueryなどを活用している企業には、データ連携の観点から提案できます。"
    },
    {
      id: "llm-029",
      question: "「オープンソースLLM」の利点として正しいものはどれですか？",
      options: [
        "商用利用が必ず無料であること",
        "自社環境で運用しデータを外部送信しなくて済む",
        "常にプロプライエタリモデルより高性能である",
        "サポートやドキュメントが手厚いこと"
      ],
      correctIndex: 1,
      explanation: "オープンソースLLMは、自社サーバーやプライベートクラウドで運用できるため、機密データを外部に送信する必要がありません。ただし、運用には技術力が必要です。データセキュリティ要件の厳しいお客様には、オンプレミス運用の選択肢として提案できます。"
    },
    {
      id: "llm-030",
      question: "Mistral AIはどの国発のLLMスタートアップですか？",
      options: [
        "アメリカ",
        "中国",
        "フランス",
        "日本"
      ],
      correctIndex: 2,
      explanation: "Mistral AIはフランスのパリを拠点とするスタートアップで、高性能かつオープンなLLMを開発しています。EUのデータ規制対応を重視するお客様には、欧州発のAI企業として選択肢になります。"
    },
    {
      id: "llm-031",
      question: "「GPT」とは何の略ですか？",
      options: [
        "General Purpose Technology",
        "Generative Pre-trained Transformer",
        "Global Processing Tool",
        "Graphical Programming Terminal"
      ],
      correctIndex: 1,
      explanation: "GPTは「Generative Pre-trained Transformer（生成的事前学習Transformer）」の略です。名前の通り、事前学習されたTransformerベースのテキスト生成モデルです。お客様に「GPTとは何か」と聞かれた際に、正式名称と意味を説明できると信頼感が増します。"
    },
    {
      id: "llm-032",
      question: "ChatGPT Plusの主な特徴は何ですか？",
      options: [
        "完全に無料で使えるサービス",
        "月額課金でGPT-4などにアクセスできる",
        "大企業向けの専用サービス",
        "オフラインでも使えるサービス"
      ],
      correctIndex: 1,
      explanation: "ChatGPT Plusは月額課金の個人向けプランで、GPT-4、画像生成（DALL-E）、コード実行などの高度な機能を利用できます。無料版との違いを説明し、お客様の利用目的に応じて適切なプランを提案しましょう。企業利用にはEnterprise版もあります。"
    },
    {
      id: "llm-033",
      question: "Claude 3のモデルシリーズ「Opus」「Sonnet」「Haiku」の違いは何ですか？",
      options: [
        "対応している言語の違い",
        "性能と価格のバランスの違い",
        "開発された年代の違い",
        "利用できる地域の違い"
      ],
      correctIndex: 1,
      explanation: "Claude 3シリーズはOpus（最高性能）、Sonnet（バランス型）、Haiku（軽量・高速・低コスト）の3つがあります。お客様のユースケースに応じて、「複雑な分析はOpus、日常的なタスクはHaiku」といった使い分けを提案できます。"
    },
    {
      id: "llm-034",
      question: "「Copilot」とはMicrosoftのどのようなサービスですか？",
      options: [
        "航空機の自動操縦システム",
        "Office製品などに統合されたAIアシスタント",
        "Microsoftが開発したプログラミング言語",
        "Microsoftのクラウドストレージサービス"
      ],
      correctIndex: 1,
      explanation: "Microsoft CopilotはGPT技術を活用したAIアシスタントで、Word、Excel、Teams、Windowsなどに統合されています。既存のMicrosoft 365ユーザーには、普段の業務ツールにAIが組み込まれる利便性を訴求できます。"
    },
    {
      id: "llm-035",
      question: "GitHub Copilotは何を支援するAIツールですか？",
      options: [
        "文書作成",
        "プログラミング・コード作成",
        "画像編集",
        "音声認識"
      ],
      correctIndex: 1,
      explanation: "GitHub CopilotはOpenAIの技術を活用したプログラミング支援AIで、コードの自動補完や提案を行います。開発チームを持つお客様には、開発生産性向上のソリューションとして提案できます。"
    },
    {
      id: "llm-036",
      question: "「ChatGPT Enterprise」の主な特徴は何ですか？",
      options: [
        "個人向けに提供される無料サービス",
        "企業向けにセキュリティや管理機能を提供",
        "教育機関に特化した専用サービス",
        "研究者向けに提供されるAPIサービス"
      ],
      correctIndex: 1,
      explanation: "ChatGPT Enterpriseは企業向けプランで、SOC 2準拠のセキュリティ、管理コンソール、SSO対応、無制限のGPT-4利用などを提供します。大企業のセキュリティ要件やIT管理要件を満たす必要がある場合に提案できます。"
    },
    {
      id: "llm-037",
      question: "日本語に強いとされる国産LLMはどれですか？",
      options: [
        "OpenAIのGPT-4モデル",
        "ELYZAやPLaMoなどの国産モデル",
        "MetaのLLaMAモデル",
        "GoogleのPaLMモデル"
      ],
      correctIndex: 1,
      explanation: "ELYZA（PKSHA/東京大学発）、PLaMo（Preferred Networks）、Japanese StableLM（Stability AI Japan）など、日本語に特化したLLMが開発されています。日本語特有のニュアンスや敬語表現を重視するお客様には、国産モデルの選択肢を提案できます。"
    },
    {
      id: "llm-038",
      question: "Perplexityとは何ですか？",
      options: [
        "LLMの性能を測定する評価指標",
        "情報源を明示しながら回答するAI検索エンジン",
        "新しく開発されたプログラミング言語",
        "大規模データ向けのデータベース製品"
      ],
      correctIndex: 1,
      explanation: "Perplexityは、LLMを活用したAI検索エンジンで、ウェブ検索結果を元に回答し、情報源を明示します。最新情報へのアクセスとハルシネーション軽減が特徴です。「検索と要約を一度に行いたい」というお客様のニーズに応えられます。"
    },
    {
      id: "llm-039",
      question: "「GPT-4 Turbo」と「GPT-4」の主な違いは何ですか？",
      options: [
        "GPT-4 Turboの方が性能が低い",
        "知識が新しくコンテキストが大きく安い",
        "GPT-4 TurboはAPIに非対応",
        "GPT-4 Turboは日本語に非対応"
      ],
      correctIndex: 1,
      explanation: "GPT-4 Turboは、GPT-4より知識のカットオフが新しく、128Kトークンの大きなコンテキストウィンドウを持ち、料金も安くなっています。長文処理やコスト重視のお客様には、GPT-4 Turboを優先的に提案できます。"
    },
    {
      id: "llm-040",
      question: "「o1」（OpenAI o1）の特徴は何ですか？",
      options: [
        "画像生成に特化したモデル",
        "複雑な推論や数学に強いモデル",
        "音声認識専用に設計されたモデル",
        "OpenAI製品で最も安価なモデル"
      ],
      correctIndex: 1,
      explanation: "OpenAI o1は「thinking（思考）」機能を持ち、複雑な推論、数学、科学、コーディングの問題で高い性能を発揮します。ただし応答時間が長く、料金も高いです。高度な分析や推論が必要なユースケースに提案できます。"
    },

    // === ハルシネーション、バイアス、安全性（41-55） ===
    {
      id: "llm-041",
      question: "LLMの「ハルシネーション」とは何を指しますか？",
      options: [
        "高速で文章を生成する機能のこと",
        "事実と異なる情報をもっともらしく生成する現象",
        "複数の言語を同時に処理する能力のこと",
        "ユーザーの意図を正確に理解する機能のこと"
      ],
      correctIndex: 1,
      explanation: "ハルシネーション（幻覚）とは、LLMが事実ではない情報をあたかも本当のことのように自信を持って回答してしまう現象です。営業活動では「AIの回答は必ず人間が確認する運用が重要」とお客様にアドバイスし、適切な期待値を設定しましょう。"
    },
    {
      id: "llm-042",
      question: "ハルシネーションを軽減する方法として最も効果的なものはどれですか？",
      options: [
        "より長い文章で質問をする",
        "RAGで外部知識を参照させる",
        "複数のユーザーで同じ質問する",
        "「正確に」と指示を追加する"
      ],
      correctIndex: 1,
      explanation: "RAG（Retrieval-Augmented Generation）は、外部のデータベースや文書から関連情報を検索し、それを元に回答を生成する手法です。これによりハルシネーションを大幅に軽減できます。お客様には「御社の正確な情報に基づいて回答するシステム」として提案できます。"
    },
    {
      id: "llm-043",
      question: "LLMの「バイアス」問題とは何ですか？",
      options: [
        "電気的なノイズが生じる問題",
        "学習データの偏りが不公平な結果を生む問題",
        "AIの処理速度が遅くなる問題",
        "AIのコストが高騰してしまう問題"
      ],
      correctIndex: 1,
      explanation: "LLMは学習データに含まれる社会的バイアス（性別、人種、文化的偏見など）を反映してしまう可能性があります。採用支援や審査業務などでAIを使う場合は、バイアスの検証と人間によるチェック体制の構築が重要です。"
    },
    {
      id: "llm-044",
      question: "「RLHF」とは何の略で、何を目的としていますか？",
      options: [
        "Real-time Language Helper - リアルタイム翻訳",
        "Reinforcement Learning from Human Feedback - 強化学習",
        "Rapid Learning for High Frequency - 高速学習",
        "Responsive Language Handling - 言語処理"
      ],
      correctIndex: 1,
      explanation: "RLHFは「人間のフィードバックによる強化学習」の略で、人間の評価者がAIの回答を評価し、その結果をモデルの改善に活用する手法です。これにより、AIをより安全で有用なものにします。営業では「AIの安全性を高める最新技術を採用」と説明できます。"
    },
    {
      id: "llm-045",
      question: "LLMの「ジェイルブレイク」とは何ですか？",
      options: [
        "AIをテーマにした脱獄ゲーム",
        "安全対策を回避して有害出力を引き出す攻撃",
        "刑務所向けのAIシステムのこと",
        "AIの処理速度を上げるテクニック"
      ],
      correctIndex: 1,
      explanation: "ジェイルブレイクは、特殊なプロンプトでLLMの安全対策を回避し、通常は拒否される有害な出力を引き出そうとする攻撃手法です。お客様には「セキュリティ対策済みのエンタープライズ版の利用」や「出力のモニタリング体制」の重要性を説明しましょう。"
    },
    {
      id: "llm-046",
      question: "「コンテンツフィルタリング」とは何ですか？",
      options: [
        "AIの出力からファイルを抽出する機能",
        "有害なコンテンツを検知・ブロックする機能",
        "AIの回答を短く要約して表示する機能",
        "著作権コンテンツを検出して警告する機能"
      ],
      correctIndex: 1,
      explanation: "コンテンツフィルタリングは、暴力的、性的、違法な内容などの不適切なコンテンツの入出力を検知・ブロックする機能です。Azure OpenAI Serviceなどのエンタープライズサービスでは、この機能をカスタマイズできます。"
    },
    {
      id: "llm-047",
      question: "「プロンプトインジェクション」攻撃とは何ですか？",
      options: [
        "AIに大量のプロンプトを送信する攻撃",
        "悪意ある指示を紛れ込ませAIを操作する攻撃",
        "プロンプトの内容を暗号化して送る攻撃",
        "AIに設定されたプロンプトを盗み出す攻撃"
      ],
      correctIndex: 1,
      explanation: "プロンプトインジェクションは、ユーザー入力に悪意ある指示を紛れ込ませ、システムプロンプトを無視させたり、意図しない動作をさせようとする攻撃です。AI搭載システムの開発では、入力の検証やサンドボックス化などの対策が必要です。"
    },
    {
      id: "llm-048",
      question: "LLMの「説明責任」として重要な考え方はどれですか？",
      options: [
        "AIの出力は常に正しいので説明は不要",
        "判断根拠を明示し人間が最終判断する体制",
        "AIの内部構造を全て公開すること",
        "AIの利用を必要最小限に抑えること"
      ],
      correctIndex: 1,
      explanation: "AIの説明責任では、なぜその出力に至ったかを説明でき、人間が最終的な判断と責任を持つ体制が重要です。特に重要な意思決定にAIを使う場合は、「AIは参考意見を提供し、人間が最終判断する」運用を提案しましょう。"
    },
    {
      id: "llm-049",
      question: "「Constitutional AI」とはAnthropicが提唱する何のアプローチですか？",
      options: [
        "各国の憲法を学習させるAI",
        "AIに原則を与え自己改善させる安全手法",
        "政府機関で使用する専用のAI",
        "AIの法的権利に関する議論のこと"
      ],
      correctIndex: 1,
      explanation: "Constitutional AIは、Anthropicが開発した手法で、AIに「有害な出力を避ける」などの原則を与え、自らの出力を批判・改善させます。これによりRLHFより効率的に安全なAIを構築できます。Claudeの安全性の技術的背景として説明できます。"
    },
    {
      id: "llm-050",
      question: "データプライバシーの観点で、LLM利用時に注意すべきことは何ですか？",
      options: [
        "LLMは自動暗号化されるので心配不要",
        "機密情報をプロンプトに含めないこと",
        "LLMには法的規制がないので自由に使える",
        "公開情報のみ学習しているので問題ない"
      ],
      correctIndex: 1,
      explanation: "LLMのAPIに送信したデータは、利用規約によってはモデル改善に使用される可能性があります。機密情報を扱う場合は、データが学習に使用されないプランや、オンプレミス環境の利用を検討しましょう。お客様のデータポリシーに合わせた提案が重要です。"
    },
    {
      id: "llm-051",
      question: "LLMが著作権侵害を引き起こす可能性があるケースはどれですか？",
      options: [
        "AIを使うこと自体が著作権侵害となる",
        "学習データのコンテンツをそのまま出力する場合",
        "AIの回答を論文などで引用する場合",
        "AIに著作物について質問をする場合"
      ],
      correctIndex: 1,
      explanation: "LLMが学習データに含まれる書籍や記事の内容をそのまま大量に出力する場合、著作権侵害の可能性があります。現在、各国で法整備が進行中です。お客様には「AI生成物の商用利用時は権利関係の確認が必要」とアドバイスしましょう。"
    },
    {
      id: "llm-052",
      question: "「AI幻覚」とも呼ばれるハルシネーションが特に問題になる業界はどれですか？",
      options: [
        "エンターテイメント業界",
        "医療・法律・金融など正確性重視の業界",
        "農業業界全般",
        "運輸業界全般"
      ],
      correctIndex: 1,
      explanation: "医療診断、法律アドバイス、金融判断など、誤った情報が深刻な被害につながる分野では、ハルシネーションは特に問題です。これらの業界では「AIは補助ツールとして使用し、専門家が必ず確認する」運用を強く推奨しましょう。"
    },
    {
      id: "llm-053",
      question: "LLMの安全性向上のための「レッドチーミング」とは何ですか？",
      options: [
        "赤いチームカラーで開発すること",
        "意図的に攻撃を試み脆弱性を発見するテスト",
        "緊急時対応のためのチームのこと",
        "セキュリティソフトの製品名"
      ],
      correctIndex: 1,
      explanation: "レッドチーミングは、専門家が意図的にAIシステムを攻撃・悪用しようとして、脆弱性や問題点を発見するセキュリティテスト手法です。主要なLLM開発企業はリリース前にレッドチーミングを実施しています。セキュリティに敏感なお客様への説明に活用できます。"
    },
    {
      id: "llm-054",
      question: "「モデルカード」とは何ですか？",
      options: [
        "AIモデル用のクレジットカード",
        "性能や限界、倫理事項を記載した文書",
        "AIモデルを紹介する名刺",
        "AIモデルの品質保証書"
      ],
      correctIndex: 1,
      explanation: "モデルカードは、AIモデルの性能評価、適切な使用例、限界、バイアスの可能性、倫理的考慮事項などを記載した文書です。責任あるAI開発の一環として公開されます。お客様にAIの限界を説明する際の参考資料として活用できます。"
    },
    {
      id: "llm-055",
      question: "EU AI Act（EU人工知能規則）でLLMはどのように扱われる予定ですか？",
      options: [
        "完全に全面禁止となる予定",
        "汎用AIとして透明性要件の規制対象",
        "規制対象外となる予定",
        "医療用途のみ規制対象となる"
      ],
      correctIndex: 1,
      explanation: "EU AI Actでは、LLMなどの汎用AIシステムは透明性要件（技術文書の作成、EU法への準拠など）が課されます。高リスク用途ではさらに厳しい要件があります。EUでビジネスを行うお客様には、コンプライアンス対応の必要性を説明しましょう。"
    },

    // === 料金体系、API、利用制限（56-70） ===
    {
      id: "llm-056",
      question: "多くのLLM APIの料金体系はどのようになっていますか？",
      options: [
        "月額固定料金のみ",
        "処理したトークン数に応じた従量課金",
        "1回の質問ごとの固定料金",
        "ユーザー数に応じた料金"
      ],
      correctIndex: 1,
      explanation: "多くのLLM APIは、入力トークン数と出力トークン数に応じた従量課金制です。通常、1,000トークンあたりの単価で計算されます。お客様の予想利用量から月額費用を見積もり、予算に合った提案をしましょう。"
    },
    {
      id: "llm-057",
      question: "「RPM」と「TPM」とは何を指しますか？",
      options: [
        "回転数と温度の測定単位のこと",
        "1分あたりのリクエスト数とトークン数の制限",
        "収益とコストの指標のこと",
        "品質管理の基準のことを指す"
      ],
      correctIndex: 1,
      explanation: "RPM（Requests Per Minute）は1分あたりのAPI呼び出し回数制限、TPM（Tokens Per Minute）は1分あたりの処理トークン数制限です。これらの制限を超えるとエラーになります。お客様の想定利用量に応じて、適切なプラン選択や制限緩和を提案しましょう。"
    },
    {
      id: "llm-058",
      question: "OpenAI APIの「Tier」とは何を指しますか？",
      options: [
        "AIの性能ランク",
        "利用金額に応じた利用制限の緩和レベル",
        "料金の割引率",
        "データセンターの階層"
      ],
      correctIndex: 1,
      explanation: "OpenAI APIのTierは、過去の利用金額や支払い実績に応じて設定される利用制限のレベルです。Tierが上がると、RPMやTPMの制限が緩和されます。利用量の多いお客様には、Tier昇格のプロセスを説明し、将来の拡張に備えた計画を提案しましょう。"
    },
    {
      id: "llm-059",
      question: "「ストリーミングレスポンス」とは何ですか？",
      options: [
        "AIによって動画を生成する機能",
        "回答を生成しながら少しずつ返す方式",
        "音楽ストリーミングサービスとの連携",
        "データをリアルタイムで分析する機能"
      ],
      correctIndex: 1,
      explanation: "ストリーミングレスポンスは、LLMの回答を生成しながら少しずつ返す方式です。ユーザーは回答全体の生成を待たずに読み始められるため、体感待ち時間を短縮できます。チャットボット開発では標準的に採用される方式です。"
    },
    {
      id: "llm-060",
      question: "「APIキー」の管理で最も重要な注意点は何ですか？",
      options: [
        "キーは定期的に変更する必要はない",
        "キーを公開リポジトリやフロントエンドコードに含めない",
        "キーは複数人で共有すると便利",
        "キーは長いほど安全"
      ],
      correctIndex: 1,
      explanation: "APIキーは機密情報であり、GitHubなどの公開リポジトリやフロントエンドのJavaScriptコードに含めると漏洩の危険があります。漏洩すると第三者に悪用され、高額な請求が発生する可能性があります。環境変数やシークレット管理サービスの利用を推奨しましょう。"
    },
    {
      id: "llm-061",
      question: "「バッチAPI」の利点は何ですか？",
      options: [
        "リアルタイム応答が速くなる",
        "大量リクエストをまとめて処理し料金が安い",
        "画像を一括で処理できるようになる",
        "複数のモデルを同時に使えるようになる"
      ],
      correctIndex: 1,
      explanation: "バッチAPIは、大量のリクエストを非同期でまとめて処理する方式で、通常のAPIより料金が割安になることが多いです（OpenAIでは50%オフ）。即座の応答が不要な大量処理（文書の一括分析など）に適しており、コスト最適化の提案に活用できます。"
    },
    {
      id: "llm-062",
      question: "「Fine-tuning API」の料金はどのように発生しますか？",
      options: [
        "学習時のみ料金が発生する",
        "学習時と推論時の両方で発生する",
        "推論時のみ料金が発生する",
        "完全に無料で利用できる"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングでは、学習データの処理に対する料金と、学習済みモデルを使用する際の推論料金（通常より高い場合が多い）の両方が発生します。総コストを見積もる際は、学習コストと継続的な利用コストの両方を考慮しましょう。"
    },
    {
      id: "llm-063",
      question: "「キャッシング」によるLLMコスト削減の仕組みはどれですか？",
      options: [
        "現金で支払うと割引を受けられる",
        "同じ質問の回答を保存し再利用する",
        "複数の契約をまとめて割引を受ける",
        "使用していない期間の料金が免除"
      ],
      correctIndex: 1,
      explanation: "キャッシングは、過去の質問と回答を保存し、同じ質問が来た場合にAPIを呼び出さずに保存済みの回答を返す仕組みです。FAQボットなど同じ質問が多いユースケースでは、大幅なコスト削減が可能です。"
    },
    {
      id: "llm-064",
      question: "「Embedding API」と「Chat API」の料金を比較すると一般的にどちらが高いですか？",
      options: [
        "Embedding APIの方が大幅に高い",
        "Chat API（生成API）の方が高い",
        "料金は同じ",
        "利用量によって逆転する"
      ],
      correctIndex: 1,
      explanation: "一般的に、テキスト生成を行うChat APIの方が、ベクトル変換のみを行うEmbedding APIより料金が高いです。RAGシステムでは、検索（Embedding）と生成（Chat）でAPIを使い分けることで、コスト効率の良いシステムを構築できます。"
    },
    {
      id: "llm-065",
      question: "「レート制限エラー」が発生した場合の適切な対処法は何ですか？",
      options: [
        "すぐに同じリクエストを再送する",
        "待ち時間を延ばしながら再試行する",
        "新しいAPIキーに変更する",
        "別のモデルに切り替えて対応"
      ],
      correctIndex: 1,
      explanation: "レート制限エラー（429エラー）が発生した場合は、指数バックオフ（1秒、2秒、4秒...と待ち時間を延ばしながら再試行）を実装するのが一般的です。すぐに再送すると制限が続くため逆効果です。開発チームには適切なエラーハンドリングの実装を推奨しましょう。"
    },
    {
      id: "llm-066",
      question: "「SLA（Service Level Agreement）」でLLM APIにおいて保証される主な項目は何ですか？",
      options: [
        "AIの回答精度",
        "稼働率（アップタイム）やレスポンス時間",
        "ハルシネーションの発生率",
        "トレーニングの効果"
      ],
      correctIndex: 1,
      explanation: "LLM APIのSLAでは主に稼働率（例：99.9%）やサポート対応時間などが保証されます。回答精度やハルシネーション率は保証対象外です。エンタープライズ契約では、お客様の業務要件に合うSLAを確認しましょう。"
    },
    {
      id: "llm-067",
      question: "OpenAI APIの「Assistants API」とは何ですか？",
      options: [
        "人間のアシスタントを手配するサービス",
        "会話やファイル処理機能を備えた構築用API",
        "音声アシスタント専用に設計されたAPI",
        "カスタマーサポート用の電話システムAPI"
      ],
      correctIndex: 1,
      explanation: "Assistants APIは、会話履歴の管理、ファイルのアップロード・検索、コード実行、関数呼び出しなどの機能を統合的に提供するAPIです。複雑なAIアシスタントを構築する際に、これらの機能を自前で実装する手間を省けます。"
    },
    {
      id: "llm-068",
      question: "「Function Calling」機能とは何ですか？",
      options: [
        "ユーザーに電話をかける機能",
        "LLMが外部APIを呼び出すか判断する機能",
        "関数型プログラミングでAIを開発する方式",
        "AIが数学の関数を計算する機能"
      ],
      correctIndex: 1,
      explanation: "Function Calling（関数呼び出し）は、LLMがユーザーの質問に基づいて、どの外部関数を呼ぶべきか、どんな引数を渡すべきかを判断する機能です。これにより、予約システムやデータベース検索など外部システムとの連携が容易になります。"
    },
    {
      id: "llm-069",
      question: "「JSON Mode」とは何ですか？",
      options: [
        "JSONファイルを読み込むモード",
        "LLMの出力を必ずJSON形式にする設定",
        "データベース接続モード",
        "JavaScript専用のAPI"
      ],
      correctIndex: 1,
      explanation: "JSON Modeは、LLMの出力を必ず有効なJSON形式にする設定です。APIレスポンスをプログラムで処理する際に、パースエラーを防げます。システム連携やデータ抽出タスクでは必須の設定として推奨しましょう。"
    },
    {
      id: "llm-070",
      question: "「コスト上限設定」の重要性として正しいものはどれですか？",
      options: [
        "設定しなくても問題ない",
        "予期せぬ大量利用による高額請求を防ぐために重要",
        "設定すると性能が下がる",
        "エンタープライズプランでは不要"
      ],
      correctIndex: 1,
      explanation: "コスト上限設定は、プログラムのバグや予期せぬ大量アクセスによる高額請求を防ぐ安全装置です。開発段階や本番環境でも必ず設定することを推奨しましょう。過去に設定なしで数百万円の請求が発生した事例もあります。"
    },

    // === プロンプトの基本（71-82） ===
    {
      id: "llm-071",
      question: "「プロンプト」とは何ですか？",
      options: [
        "AIの応答時間",
        "LLMに対する入力文（指示や質問）",
        "AIの性能指標",
        "AIのエラーメッセージ"
      ],
      correctIndex: 1,
      explanation: "プロンプトは、LLMに対して送る入力文のことで、質問、指示、文脈情報などを含みます。プロンプトの書き方次第で回答の質が大きく変わるため、プロンプトエンジニアリングというスキルが重要になっています。"
    },
    {
      id: "llm-072",
      question: "「システムプロンプト」の役割は何ですか？",
      options: [
        "システムエラーを報告するプロンプト",
        "AIの役割や振る舞いのルールを設定するプロンプト",
        "OSを起動するコマンド",
        "管理者用の特別なプロンプト"
      ],
      correctIndex: 1,
      explanation: "システムプロンプトは、AIに「あなたは〇〇の専門家です」「丁寧な敬語で回答してください」といった役割や振る舞いのルールを設定するプロンプトです。一貫した応答を得るための基盤となり、チャットボット開発で重要な役割を果たします。"
    },
    {
      id: "llm-073",
      question: "効果的なプロンプトの書き方として正しいものはどれですか？",
      options: [
        "できるだけ短く曖昧に書く",
        "具体的な指示と出力形式を明確に記述",
        "専門用語をできるだけ多く使う",
        "感情的な表現を多く使う"
      ],
      correctIndex: 1,
      explanation: "効果的なプロンプトは、具体的な指示、期待する出力形式（例：箇条書き、JSON形式）、必要な背景情報を明確に含みます。「分かりやすく説明して」より「初心者向けに3つのポイントで説明して」の方が良い結果が得られます。"
    },
    {
      id: "llm-074",
      question: "「Chain of Thought（思考の連鎖）」プロンプティングとは何ですか？",
      options: [
        "複数のAIを連結させる手法",
        "AIに段階的に考えさせることで推論精度を向上させる手法",
        "連続して質問を送る手法",
        "AIの思考を視覚化する手法"
      ],
      correctIndex: 1,
      explanation: "Chain of Thought（CoT）は、「ステップバイステップで考えてください」などの指示により、AIに推論過程を明示させる手法です。数学問題や論理的推論タスクで精度が向上します。複雑な分析タスクでは「まず〇〇を分析し、次に△△を検討してください」と段階を指定しましょう。"
    },
    {
      id: "llm-075",
      question: "「ロールプレイ」プロンプティングの効果は何ですか？",
      options: [
        "ゲームをプレイさせること",
        "AIに専門家を演じさせ視点を得る",
        "ユーザーに役割を割り当てる",
        "AIの演技力を評価すること"
      ],
      correctIndex: 1,
      explanation: "「あなたは10年経験のあるマーケティング専門家です」のように役割を与えると、AIはその視点から回答します。お客様の業界や用途に合わせた専門家ロールを設定することで、より適切な回答を得られます。"
    },
    {
      id: "llm-076",
      question: "「制約条件」をプロンプトに含める効果は何ですか？",
      options: [
        "AIの全体的な性能が下がる",
        "出力を制御し用途に適した回答を得る",
        "AIの処理速度が向上する",
        "APIの利用料金が安くなる"
      ],
      correctIndex: 1,
      explanation: "「100文字以内で」「専門用語を使わずに」「箇条書きで3点」などの制約条件を含めると、AIの出力を制御できます。業務用途では、出力形式を統一することでシステム連携や品質管理が容易になります。"
    },
    {
      id: "llm-077",
      question: "「プロンプトテンプレート」を使用する利点は何ですか？",
      options: [
        "AIの処理速度が向上する",
        "一貫した品質と作成効率の向上",
        "APIの料金が割引される",
        "AIの学習に使用される"
      ],
      correctIndex: 1,
      explanation: "プロンプトテンプレートは、変数部分（顧客名、製品名など）を埋め込むだけで使えるプロンプトの雛形です。チーム全体で品質を統一でき、作成効率も上がります。お客様には「御社専用のプロンプトテンプレート集」の作成を提案できます。"
    },
    {
      id: "llm-078",
      question: "「ネガティブプロンプト」とは何ですか？",
      options: [
        "否定的な質問をすること",
        "AIに「してほしくないこと」を明示的に指示すること",
        "AIを批判するプロンプト",
        "エラーを発生させるプロンプト"
      ],
      correctIndex: 1,
      explanation: "ネガティブプロンプトは、「〜しないでください」「〜を含めないでください」のように、AIに避けてほしい行動を明示する指示です。画像生成AIでは「不要な要素の除外」、テキスト生成では「専門用語を使わない」などに活用されます。"
    },
    {
      id: "llm-079",
      question: "「プロンプトチェーン」とは何ですか？",
      options: [
        "プロンプトを暗号化すること",
        "複数のプロンプトを連続実行する手法",
        "プロンプトをブロックチェーンに記録",
        "複数のAIを同時に使うこと"
      ],
      correctIndex: 1,
      explanation: "プロンプトチェーンは、「まず要約を作成」→「要約を元に質問を生成」→「質問に回答」のように、複数のプロンプトを連続して実行する手法です。複雑なタスクを分解して精度を向上させられます。"
    },
    {
      id: "llm-080",
      question: "プロンプトの「デリミター」とは何ですか？",
      options: [
        "プロンプトを削除するコマンド",
        "セクションを区切る記号（###など）",
        "プロンプトの長さ制限のこと",
        "プロンプトの暗号化キーのこと"
      ],
      correctIndex: 1,
      explanation: "デリミターは、プロンプト内で指示文、入力データ、例などを明確に区切る記号です。「###指示###」「```入力データ```」のように使用します。これにより、AIがプロンプトの構造を正確に理解しやすくなります。"
    },
    {
      id: "llm-081",
      question: "「プロンプトの最適化」で重要なアプローチは何ですか？",
      options: [
        "一度作成したら変更しないこと",
        "A/Bテストで比較し継続的に改善",
        "できるだけ長いプロンプトを使う",
        "英語のプロンプトのみ使用する"
      ],
      correctIndex: 1,
      explanation: "プロンプトの最適化では、複数のバリエーションを作成してA/Bテストで効果を比較し、継続的に改善することが重要です。同じタスクでも、プロンプトの書き方次第で精度が大きく変わるため、本番運用前に十分なテストを行いましょう。"
    },
    {
      id: "llm-082",
      question: "「プロンプトエンジニアリング」が営業で重要な理由は何ですか？",
      options: [
        "プログラミングスキルの代わりになる",
        "追加開発なしでAIの効果を最大化できる",
        "プロンプトエンジニアを雇わなくてよい",
        "AIの利用料金を無料にできるから"
      ],
      correctIndex: 1,
      explanation: "プロンプトエンジニアリングは、ファインチューニングなどの追加開発なしで、プロンプトの工夫だけでAIの効果を大幅に向上させられる手法です。導入コストを抑えつつ効果を出したいお客様には、プロンプト設計支援をセットで提案しましょう。"
    },

    // === ファインチューニング、RAG（83-92） ===
    {
      id: "llm-083",
      question: "「ファインチューニング」とは何ですか？",
      options: [
        "AIの音質を調整すること",
        "事前学習済みモデルを特定のデータで追加学習させること",
        "AIの料金を調整すること",
        "プロンプトを最適化すること"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは、事前学習済みのLLMを、お客様固有のデータや用途に合わせて追加学習させることです。独自の文体、専門知識、特定のタスクへの対応力を向上させられます。ただし、コストと効果のバランスを検討する必要があります。"
    },
    {
      id: "llm-084",
      question: "ファインチューニングが特に有効なケースはどれですか？",
      options: [
        "一般的な質問応答のタスク",
        "独自の文体で一貫した出力が必要な場合",
        "最新ニュースについての質問",
        "単純な翻訳タスクの処理"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングは、特定の文体（例：企業のトーン&マナー）、独自のフォーマット、専門用語の正確な使用が必要な場合に効果的です。お客様のブランドガイドラインに沿った文章生成などに活用できます。"
    },
    {
      id: "llm-085",
      question: "「RAG（Retrieval-Augmented Generation）」とは何ですか？",
      options: [
        "AIの一種のブランド名のこと",
        "外部DBから検索し回答を生成する手法",
        "AIの学習速度を上げる技術",
        "高品質な画像を生成する技術"
      ],
      correctIndex: 1,
      explanation: "RAG（検索拡張生成）は、質問に関連する情報を外部データベースや文書から検索し、その情報をコンテキストとしてLLMに渡すことで、正確で最新の情報に基づいた回答を生成する手法です。社内文書を活用したAIチャットボットの基盤技術として提案できます。"
    },
    {
      id: "llm-086",
      question: "RAGとファインチューニングの使い分けとして適切なものはどれですか？",
      options: [
        "どちらも同じ効果なので好みで選べばよい",
        "最新情報にはRAG、文体統一にはファインチューニング",
        "RAGは高額でファインチューニングは低額となる",
        "RAGは英語専用でファインチューニングは日本語専用"
      ],
      correctIndex: 1,
      explanation: "RAGは外部データを参照するため最新情報への対応や頻繁な更新に強く、ファインチューニングはモデル自体の振る舞いを変えるため一貫した文体やフォーマットの実現に適しています。お客様の要件に応じて、どちらか、または両方の組み合わせを提案しましょう。"
    },
    {
      id: "llm-087",
      question: "RAGシステムで使用される「ベクトルデータベース」の役割は何ですか？",
      options: [
        "画像を保存するためのデータベース",
        "テキストのベクトルを保存し類似検索を行う",
        "AIのパラメータを保存するデータベース",
        "ユーザー情報を管理するデータベース"
      ],
      correctIndex: 1,
      explanation: "ベクトルデータベース（Pinecone、Weaviate、Chromaなど）は、テキストを変換した高次元ベクトルを保存し、質問ベクトルと類似した文書を高速に検索します。RAGシステムの「検索」部分を担う重要なコンポーネントです。"
    },
    {
      id: "llm-088",
      question: "RAGシステムの「チャンク」とは何ですか？",
      options: [
        "長文を検索しやすいサイズに分割した断片",
        "データ処理中に発生するエラーメッセージ",
        "APIリクエストを送信する際の単位",
        "AIサービスの料金を計算する単位"
      ],
      correctIndex: 0,
      explanation: "チャンクは、長い文書を検索に適したサイズに分割した断片です。チャンクサイズの設計は検索精度に大きく影響し、小さすぎると文脈が失われ、大きすぎると関連性の低い情報が含まれます。RAGシステム構築では重要な設計ポイントです。"
    },
    {
      id: "llm-089",
      question: "「LoRA（Low-Rank Adaptation）」とは何ですか？",
      options: [
        "低性能なAI",
        "少ないパラメータで効率的にファインチューニングを行う手法",
        "AIの音声処理技術",
        "低解像度の画像生成"
      ],
      correctIndex: 1,
      explanation: "LoRAは、モデル全体ではなく小さな追加パラメータのみを学習する効率的なファインチューニング手法です。学習コストとストレージを大幅に削減でき、複数の用途向けモデルを低コストで運用できます。コスト効率重視のお客様に提案できます。"
    },
    {
      id: "llm-090",
      question: "ファインチューニング用のデータ準備で重要なことは何ですか？",
      options: [
        "データ量は少ないほど良い結果が出る",
        "高品質で一貫性のある入出力ペアを用意",
        "個人情報を多く含めて学習させる",
        "他社のデータを許可なく使用する"
      ],
      correctIndex: 1,
      explanation: "ファインチューニングでは、高品質で一貫性のある入出力ペア（質問と理想的な回答のセット）が重要です。品質の低いデータで学習すると、モデルの性能も低下します。お客様には「良いデータの準備がファインチューニング成功の鍵」と伝えましょう。"
    },
    {
      id: "llm-091",
      question: "「ハイブリッド検索」とは何ですか？",
      options: [
        "複数のAIを組み合わせること",
        "ベクトル検索とキーワード検索を組み合わせる手法",
        "オンラインとオフラインを組み合わせること",
        "画像とテキストを組み合わせること"
      ],
      correctIndex: 1,
      explanation: "ハイブリッド検索は、意味の類似性を捉えるベクトル検索と、特定のキーワードを正確に検索するキーワード検索を組み合わせる手法です。RAGシステムで検索精度を向上させるために用いられます。"
    },
    {
      id: "llm-092",
      question: "RAGシステムの「リランキング」とは何ですか？",
      options: [
        "検索結果の順位を上げること",
        "検索結果を再評価し関連性順に並べ替える",
        "ユーザーの順位を決めること",
        "AIモデルをランク付けすること"
      ],
      correctIndex: 1,
      explanation: "リランキングは、最初の検索で得られた結果を、より精度の高いモデルで再評価し、質問への関連性が高い順に並べ替えるプロセスです。検索精度を向上させ、RAGシステムの回答品質を高められます。"
    },

    // === マルチモーダル（93-96） ===
    {
      id: "llm-093",
      question: "「マルチモーダルAI」とは何ですか？",
      options: [
        "複数のAIを同時に使うこと",
        "テキストや画像など複数種類のデータを処理できるAI",
        "複数の言語に対応したAI",
        "複数のユーザーが使えるAI"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAIは、テキストだけでなく、画像、音声、動画など複数の種類（モダリティ）のデータを理解・生成できるAIです。GPT-4V、Gemini、Claude 3などが画像理解に対応しています。「画像を見せて質問できる」機能として、様々な業務活用が可能です。"
    },
    {
      id: "llm-094",
      question: "GPT-4Vの「V」は何を意味しますか？",
      options: [
        "Version",
        "Vision（視覚・画像理解）",
        "Virtual",
        "Velocity"
      ],
      correctIndex: 1,
      explanation: "GPT-4Vの「V」はVision（視覚）を意味し、画像を入力として受け取り、内容を理解・説明できる機能を指します。写真の説明、図表の分析、文書のスキャンデータからの情報抽出など、画像を含む業務に活用できます。"
    },
    {
      id: "llm-095",
      question: "マルチモーダルAIのビジネス活用例として適切なものはどれですか？",
      options: [
        "テキストのみの翻訳を行う処理",
        "製品画像から説明文生成、手書きメモのデジタル化",
        "単純な計算処理を高速化する",
        "データベースの管理を行う処理"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAIは、製品写真からの説明文生成、手書きメモや名刺のデジタル化、図面や設計図の解析、医療画像の説明など、画像とテキストを組み合わせた業務に活用できます。お客様の業務で画像を扱う場面を探し、活用提案しましょう。"
    },
    {
      id: "llm-096",
      question: "マルチモーダルAIの利用時の注意点は何ですか？",
      options: [
        "画像は何でも送信して問題ない",
        "機密画像や人物のプライバシーに注意が必要",
        "画像は自動的に暗号化される",
        "画像処理は常に無料で利用できる"
      ],
      correctIndex: 1,
      explanation: "マルチモーダルAI利用時は、機密文書の画像、個人情報を含む写真、著作権のある画像の取り扱いに注意が必要です。また、画像処理は通常のテキスト処理より料金が高い場合が多いです。お客様には適切な利用ガイドラインの策定を推奨しましょう。"
    },

    // === 温度パラメータ、トップP（97-100） ===
    {
      id: "llm-097",
      question: "LLMの「Temperature（温度）」パラメータの役割は何ですか？",
      options: [
        "AIの処理速度を制御する",
        "出力のランダム性や創造性を制御する",
        "AIの消費電力を制御する",
        "AIの学習速度を制御する"
      ],
      correctIndex: 1,
      explanation: "Temperature（温度）は、出力のランダム性を制御するパラメータです。0に近いほど一貫した確定的な出力、1に近いほど多様で創造的な出力になります。事実確認には低め（0.2〜0.3）、創作には高め（0.7〜0.9）を推奨しましょう。"
    },
    {
      id: "llm-098",
      question: "「Top-P（トップP）」パラメータとは何ですか？",
      options: [
        "最高性能を意味する指標のこと",
        "確率上位の単語候補から選択する方式",
        "上位P人のユーザーのみ使える機能",
        "AIの精度を表す数値のこと"
      ],
      correctIndex: 1,
      explanation: "Top-P（nucleus sampling）は、確率の高い順に単語を並べ、累積確率がPに達するまでの候補から次の単語を選択する方式です。0.1なら上位10%の確率の単語から選択。Temperatureと組み合わせて出力の多様性を制御します。"
    },
    {
      id: "llm-099",
      question: "ビジネス文書作成に適したTemperature設定はどれですか？",
      options: [
        "1.0以上の高い値",
        "0.3〜0.5程度の低めの値",
        "設定は不要",
        "毎回ランダムに変える"
      ],
      correctIndex: 1,
      explanation: "ビジネス文書やFAQ回答など、一貫性と正確性が求められる用途では、Temperature 0.3〜0.5程度の低めの設定が適しています。一方、マーケティングコピーやアイデア出しでは0.7〜0.9の高めの設定で創造性を引き出せます。"
    },
    {
      id: "llm-100",
      question: "企業でLLMを導入する際の成功のポイントとして最も重要なものはどれですか？",
      options: [
        "最も高価なモデルを選ぶこと",
        "明確なユースケース特定と段階的な導入検証",
        "全業務を一度にAI化すること",
        "AIに全ての判断を任せること"
      ],
      correctIndex: 1,
      explanation: "LLM導入の成功には、まず明確なユースケース（例：カスタマーサポート、文書要約）を特定し、小規模なPoC（概念実証）から始めて効果を検証し、徐々に拡大するアプローチが重要です。営業では「一緒に最適な導入計画を策定しましょう」と提案し、伴走型の支援を提供しましょう。"
    }
  ]
};
